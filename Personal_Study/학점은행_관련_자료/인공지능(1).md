# 인공지능 (1)

# 인공지능 정의

- 대표적인 정의
    - 사람처럼 행동하도록 만들어진 장치 또는 소프트웨어
    - 장치가 프로그램을 통해 판단하고, 결정을 위한 의사가 있는 것처럼 행동하는 것
    - 지능(의사결정)을 인공적(소프트웨어)으로 만들어 내는 것
    - 생물학적 의미를 포함하지 않음
- 과학자들의 정의
    - John McCarthy
        - 학습과 기타 다른 지능의 특징을 기계가 시뮬레이션 할 수 있을 것
    - Patrick Henry Winston
        - 컴퓨터가 지능을 가질 수 있도록 하는 아이디어를 연구하는 학문
    - Charniak & McDermott
        - 계산 모델을 이용하여 정신적 기반을 연구하는 학문
- 인공지능에 공헌한 과학자들
    - John McCarthy
        - 미국의 전산학자이자 인지과학자
        - 1971년 튜링상 수상
        - LISP 언어 설계 및 구현
        - 인공지능이라는 용어 창안
    - Marvin Lee Minsky
        - 인공지능 분야를 개척한 미국인 과학자
        - MIT의 인공지능 연구소의 공동 설립자
        - AI와 관련된 책들을 저술
- 인공지능의 범주
    
    ![Untitled](인공지능(1)/Untitled.png)
    
    - Vision
        - 사람들이 보고 있는 특정 피사체 사진의 정체를 확인하고자 시도하는 기술(ImageRecognition/Machine Vision)
    - Planning
        - 데이터 마이닝, 자동 추론 등을 활용해 의사결정에 이용하는 과정
        - 초기 상태에서 문제 해결 상태로의 이동을 위한 Search Problem
    - Speech
        - 음성 인식, 인간이 발성하는 음성을 이해하여 컴퓨터가 다룰 수 있는 문자(코드) 정보로 변환하는 기술(Speech to Text/Text to Speech)
            
            ![Untitled](인공지능(1)/Untitled%201.png)
            
    - Robotics
        - 인지로봇 공학은 제한된 계산 자원을 사용해 복잡한 환경의 복잡한 목표를 달성하도록 하는 인식능력을 로봇에게 부여하는 기술
    - Natural Language Processing
        - 컴퓨터가 인간의 언어를 알아들을 수 있게 하여 인간처럼 말하고 쓸 수 있도록 하는 기술
            
            ![Untitled](인공지능(1)/Untitled%202.png)
            
    - Machine Learning
        - 기존 프로그램화된 논리(로직)나 정형화된 규칙 등을 바탕으로 발생되는 데이터를 통해 학습하는 수학적 알고리즘
            
            ![Untitled](인공지능(1)/Untitled%203.png)
            
- 초창기 인공지능
    - 초창기 컴퓨터의 등장
        - 단순한 조건 분기가 공장 자동 제어에 큰 비중을 차지
        - 기계가 작업을 자동화한다는 점에서 인공지능에 비유
        - 지금은 사람을 대체하는 단순한 작업의 경우에는 인공지능이라 하지 않음
    - 두번째 단계의 인공지능
        - 입력과 출력의 개수가 극단적으로 많은 경우
        - 적절한 판단을 위해 추론 또는 탐색, 저장된 지식 사용
        - 간단한 퍼즐이나 진단 프로그램 등
- 현대의 인공지능
    - 패턴 인식이나 퍼지 이론, 딥 러닝, 자율 학습 등 다양한 분야에서 다양한 이론들을 배경으로 적용되고 활용됨
    - 단순히 위의 이론이 적용된 기술들을 인공지능이라고 하지 않음
    - 강 인공지능
        - 어떤 문제를 스스로 생각하고 해결할 수 있는 사물(기계)에 적용되는 인공지능
    - 약 인공지능
        - 규칙에 따라 동작하며 지능을 흉내 내는 컴퓨터 프로그램에 적용되는 인공지능
- 요약
    - 사람처럼 행동하도록 만들어진 장치 또는 소프트웨어이다.
    - 장치가 프로그램을 통해 판단하고 결정할 수 있는 것처럼 행동하는 것이다.
    - 지능을 인공적으로 만들어 내는 것이다.

# 인공지능의 탄생

- 인공지능 용어의 탄생
    - 수학, 컴퓨터 과학 이론
        - “Computing Machinery and Intelligence” (1950, 앨런 튜링)
        - 튜링 테스트와 튜링 머신의 개념 고안
        - 다트머스 학회(1956)에서 존 매카시가 AI라는 용어 창안
    - 생리학적 측면
        - 사이버네틱스(인공두뇌학)
        - 신경망
            - 정보 전달 모델링에 관한 이론
            - 헵의 법칙(시냅스 가소성)
- 시냅스 가소성
    - 학습에 의해 시냅스가 일정한 변화가 생기는 것
    - 시냅스 강화
        - 시냅스를 통해 신경 전달 물질(자극)을 많이 전달하거나 반복적으로 학습을 하면 두 뉴런 사이의 관계 강화
    - 시냅스 약화
        - 시냅스를 통해 신경 전달 물질을 적게 전달하면 두 뉴런 사이의 관계 약화
    - 기억력과 학습 능력을 형성하는데 밀접한 관계
        
        ![Untitled](인공지능(1)/Untitled%204.png)
        
    - 전자계산기가 과학적 계산 외에 결과 판정 기계로 사용
    - 결정 트리 기반의 2차원 분류를 축적하여 자동으로 판정 결과 출력
        
        ![Untitled](인공지능(1)/Untitled%205.png)
        
- 요약
    - 존 매카시가 1956년 다트머스 학회에서 AI라는 용어를 처음 창안하였다.
    - 초창기 공장 자동화 등에 사용되었던 인공 지능이 현재에는 스스로 문제를 생각하고 해결하는 수준까지 발전하였다.
    - 패턴인식, 음성 인식, 플래닝, 머신 러닝, 전문가 시스템, 자연어 처리, 로봇공학 등 다양한 분야를 포함하며 발전 중이다.

# 튜링 테스트와 인공지능

- 튜링 테스트
    - 문제의 해답 또는 결정이 사람이 한 것인지 아니면 기계가 한 것인지를 판단
        
        ![Untitled](인공지능(1)/Untitled%206.png)
        
    - 앨런 튜링
        - 영국의 수학자, 암호학자, 논리학자
        - 컴퓨터 과학의 선구자
        - 알고리즘과 계산 개념을 튜링 기계라는 추상 모델을 통해 형식화
        - 이론 컴퓨터 과학과 인공지능에 지대한 공헌을 하여 컴퓨터 과학의 아버지로 불림
        - 튜링 테스트를 고안
- 튜링 테스트와 프로그램들
    - ELIZA(1966)
        - 1966년 MIT 인공지능 연구실에서 제작한 최초의 자연어 처리 컴퓨터 프로그램
        - 상담원과 같은 반응을 보이도록 작동
        - 튜링 테스트에 통과할 가능성이 높았던 최초의 프로그램
    - PARRY(1972)
        - 정신 분열증을 앓고 있는 사람과 같은 반응을 보이도록 작동하는 기계
    - Jugene(2014)
        - 13세의 소년과 같은 반응을 보이도록 작동한 슈퍼컴퓨터
        - 2014년 튜링 테스트에서 최초로 통과
- 인공지능의 트렌드
    - 인공지능 기술 분야별 시장 규모 전망
    - 2014년 62억 달러 규모의 스마트 머신 시장은 2019년까지 매년 20% 정도의 성장율을 보일 것으로 예상
    - 자율형 로봇 시장 규모가 2014년 12억 달러에서 2024년에는 139억 달러로 높은 성장을 보일 것으로 예상
    - 국내 동향 : 미래창조과학부
        - ICBMS(Internet of Things, Cloud, Biddata, Mobile, Security) 초연결사회에 초점을 맞춤
        - IoT의 202년 시장 규모를 2,628억 달러로 예상
        - 제품 중심이 아닌 서비스 산업으로의 변화 예측
        - 빅데이터: 인공지능 분야가 활성화된 결정적 분야
        - 인공지능의 다양한 분야와 기술이 빅데이터와 접목되어 클라우드를 통해 활용되고 수많은 비즈니스 도구로 변화
    - Deepfake
        - 인공지능의 영상 합성 및 조작 기술
        - 단순 컴퓨터 그래픽으로 만들면 인력과 시간이 필요한 기술을 인공지능으로 활용
        - 예) Synthesia에서 제작한 데이비드 베컴의 말라리아 캠페인 영상
        - 언어의 장벽을 해소
    - 해킹의 AI화
        - AI 알고리즘들은 대부분 오픈소스
        - 오픈소스의 약점을 이용한 해킹으로 AI를 공격할 수 있음
        - 또는 AI를 이용한 해킹이 있을 수 있음
    - AutoML
        - Machine Lerning을 세상에 존재하는 문제들에 자동으로 적용
        - 시간이 오래 걸리는 반복적인 작업을 자동화 하여 효율과 생산성을 높임
        - 많은 회사들과 개인들의 AI 접근 진입 장벽을 낮춤
        - AI 전문가는 부족하지만 AutoML로 전문가의 필요성이 줄어듦
        - AI 사용 시 필요한 비용과 복잡도가 낮아짐
    - Federated Learning
        - 블록 체인의 사생활 보호 방식과 비슷한 컨셉
        - 개인의 데이터는 개인의 Device에 저장하고 알고리즘은 클라우드에 저장하여 업데이트 용도로만 사용
        - 개인의 데이터 보안을 보장하면서 AI를 활용
        - 미래에는 데이터 공유가 가능해질 수도 있
- 요약
    - 앨런 튜링이 ‘사람을 대신하는 기계의 답변이 사람의 답변과 구별되지 않는 시대가 올 것’라고 하며 튜링 테스트에 반영하였다.
    - 튜링 테스트란 컴퓨터와 사람을 판별자가 각각 보이지 않는 상황에서 대화를 한 후 컴퓨터가 대답한 것을 사람이 대답한 것인지 컴퓨터가 대답한 것인지 판단하는 테스트이다.

# 인공지능의 붐과 신경망의 암흑기

- 인공지능 발전 흐름
    
    ![Untitled](인공지능(1)/Untitled%207.png)
    
- 1960 ~ 1980 : 전문가 시스템과 1차 인공지능 붐
    - 1950년 이후 조건 분기를 사용하는 규칙 기반 자동 판정 프로그램 발전
    - 추론 엔진과 전문가 시스템 등장
        - 추론 엔진
            - 프로그램의 규칙을 이용해 새로운 사실을 탐색
        - 전문가 시스템
            - 일반인도 기계가 판단한 지식 탐구의 결과를 참고할 수 있도록 전문가가 실행하는 조건 판단을 프로그램화 한 문제 처리 시스템
    - 전문가 시스템의 종류
        - Dendral
            - 알려지지 않은 유기화합물에 질량 분석법을 적용해 화합물의 구조를 파악해서 분석하고, 화학자가 해야 할 일을 자동화한 최초의 전문가 시스템
        - MYCIN
            - 감염성 질병을 진단하고, 항생제를 처방하고, 그 추론을 자세히 설명하도록 프로그래밍화 된 의료 현장에서 사용되는 전문가 시스템
    - 인공지능이 풀어야 할 과제 논의
        - 사고 범위 문제
            - 존 매카시와 패트릭 헤이즈가 제시
            - 인공지능은 제한된 범위에서만 정보를 처리하므로 실제 발생하는 문제를 모두 처리할 수 없음
- 1980 ~ 2000년 : 2차 인공지능 붐과 신경망의 암흑기
    - H/W의 지속적인 개발과 발전으로 메모리와 CPU의 성능이 급속히 발전함
    - 처리 속도의 비약적 발전으로 인한 인공지능 연구가 활발하게 됨
    - 신경망 연구가 발전했던 시기
        - 이전의 신경망 연구
            - 단순 퍼셉트론 (다수의 입력 노드와 하나의 출력 노드)
            - 패턴 인식 알고리즘
        - 이전 신경망의 문제
            - 배타적 논리합을 처리하지 못함
            - 사고 범위 문제 계산을 위한 처리속도가 미비
    - 다층 퍼셉트론(입력층, 은닉층, 출력층) 과 오차 역전파법으로 위 두 가지 문제를 해결
    - 사고 범위 문제는 여전히 한계
        
        ![Untitled](인공지능(1)/Untitled%208.png)
        
- 2000 ~ 2010년 : 통계 기반 머신러닝과 분산 처리 기술의 발전
    - 통계 기반 머신 러닝의 연구(1)
        - 분류(Classification)
            - 정해진 기준에 맞춰 데이터를 나누는 것
        - 예측(Prediction)
            - 데이터를 활용하여 앞으로 필요한 결과를 도출하는 것
        - 분류와 예측을 통해 특징량(Feature) 추출
            - 구성 요소와 기여도를 사람이 직접 확인
            - 추가 분석을 통해 통계 모델링 하여 자동 처리에 이용
                
                ![Untitled](인공지능(1)/Untitled%209.png)
                
    - 통계 기반 머신 러닝의 연구(2)
        - 베이즈 정리
            - 마르코프 연쇄 몬테카를로 방법의 초기 형태를 핵심으로 한 통계학
            - 머신러닝 알고리즘의 기반
            - 2000년대에 베이즈 필터를 이용한 머신러닝 시스템 도입
            - 사건 A와 사건 B가 일어날 확률, 사건 A가 일어났을 때 사건 B가 일어날 확률, 사건 B가 일어났을 때 사건 A가 일어날 확률을 이용한다. (통계의 확률을 이용해 필터 생성)
            - 예) 이메일 스팸 판정, 음성 입력 시스템 노이즈 제거, 발음 식별 처리 등
                
                ![Untitled](인공지능(1)/Untitled%2010.png)
                
    - 분산 처리 기술의 발전
        - 컴퓨팅 연산 능력의 한계로 사고 범위 문제를 해결하지 못함
        - 대용량 이미지와 동영상 처리 목적으로 컴퓨팅 연산 성능이 향상
        - 대용량 데이터를 한 대의 컴퓨터로 처리하기 어려워 짐에 따라 H/W(OpenMP, CUDA)와 S/W(맵리듀스 아키텍쳐, 하둡)를 고려하는 데이터 분산 처리 기술이 주목
            
            ![Untitled](인공지능(1)/Untitled%2011.png)
            
    - 분산 처리 기술과 신경망 연구의 결합
        - 하드웨어 성능 향상과 분산 처리 기술 결합으로 신경망 연구가 활발
        - 오토인코더 등장으로 딥러닝으로 발전
            - 오토 인코더 : 신경망을 사용해 차원을 압축하는 알고리즘
                
                ![Untitled](인공지능(1)/Untitled%2012.png)
                
            - 딥러닝 : 컴퓨터 프로그래밍이 다양한 데이터의 특성을 학습하고 분류하고 판별하는 머신러닝 알고리즘의 집합
        - 5개 층 이상의 계층으로 구성된 신경망(심층 신경망) 연구
        
- 2010년 이후
    - 딥러닝 이미지 인식 프로그램의 발전
    - 그 동안 통계 기반 머신러닝의 정확도가 신경망 기반 머신 러닝보다 높다고 알려짐
    - 2012년 캐나다 토론토 대학 팀의 딥러닝 이미지 인식 프로그램이 ‘ILSVRC 2012’에서 성능 평가 1위 차지
    - 2015년 5%아래의 오류율을 갖는 딥러닝 이미지 기반 인식 프로그램 등장
    - 이미지와 메타데이터가 묶인 거대한 데이터베이스 제공으로 이미지 인식 프로그램에서 발전한 이미지 인식 엔진 개발
    - 음성 인식과 자연어 처리에도 딥러닝 활용
        - 예) 챗봇, 번역 서비스

# 다양하게 활용하는 인공지능 연구

- 자동차 업계
    - 이미지 인식 인공지능 연구를 활용
    - 자율 주행 기술과 이미지 인식 결합
        - 차체 장착 센서 데이터와 도로에 설치된 카메라 이미지 정보 결합
    - 빅데이터 기술 발전으로 전국 규모 교통량 및 사고 발생 데이터까지 처리 가능
- 광고 업계
    - 뉴스 기사 및 광고 추천 시 머신러닝 시스템을 사용
    - 사용자가 방문한 웹사이트, 페이지 기록, 쇼핑몰 사이트의 구매 이력 등을 활용한 통계 모델 설계 및 구현
    - 주 콘텐츠와 연관 콘텐츠 간의 유사성 분석이 중요
    - 광고 표시 시점이나 관련성 높은 내용을 효과적으로 제공할 수 있는 시스템 구축 시 딥러닝과 머신러닝 알고리즘 활용이 높아질 예정
- 비즈니스 인텔리전스 도구
    - 경영 전략 검토 시 매출과 이익을 예측하는 분야
    - 개인의 경험 의존에서 BI 도구로 기계화
    - BI 예측 결과 도출 시 대량의 데이터에서 연관된 정보 추출을 통한 머신러닝 알고리즘이 중요한 역할
    - 재고 관리 등에 활용
        - 데이터 분석 기술 : 구글 예측 API, 베이즈 네트워크를 이용하는 불완전 데이터 예측 프로그램
        - 데이터 처리 기술 : 구글의 빅쿼리, 아파치 하둡, 스파크
- 챗봇
    - 2000년대 초 인공지능 등을 이용한 프로그램 등장
    - 초기에는 실용성이 부족
    - 2000년대 후반 대량의 텍스트 데이터를 처리하고, 특징 추출 및 표현 모델 등장
    - 2016년 네이버의 라온, 솔트룩스의 아담 등 딥러닝 기술을 활용하여 자연스러운 대화를 하는 프로그램 등장
    - 페이스북 등 SNS 기업에서 챗봇 관련 API 공개로 자연어 처리 분야의 발전 기대
        
        ![Untitled](인공지능(1)/Untitled%2013.png)
        
- 의료 지원
    - 의료 분야 예
        - 이미지 진단 응용을 통한 암 병변의 조기 발견
        - 손목 밴드형 계측 장치를 사용한 건강 관리 시스템
    - IBM 왓슨
        - 딥러닝 기술을 통한 인지 컴퓨팅
        - 자연어 처리를 통해 대화 가능한 의사결정 지원 시스템
    - 대량의 의학 논문 및 정부 정책을 저장하여 환자의 증상과 관련된 질환 정보, 적용 가능한 의사결정 지원 시스템 구축 기대
- 로봇 산업
    - 로봇 연구의 한계
        - 지금까지 개발된 규칙 기반 장비로 움직임을 구현하는데 한계
    - 뉴로모픽 컴퓨터 개발
        - 스스로 학습해서 자율적인 움직임 제어
        - 추후 강화학습 알고리즘을 도입한 로봇 개발 진행 예정
    - 로봇 산업 적용의 예
        - 생활 : 어린이 교육용 장난감
        - 고령자를 위한 생활 도우미
        - 식재료 관리
        - 날씨를 고려한 행동 제안
        - 치매 예방 대책

# 인공지능의 미래

- 빅데이터와 디지털 클론
    - 빅데이터 기술의 발전
        - 센서 데이터를 포함한 다양한 데이터와 분석 도구 활용
        - 인공지능의 개발에 활용
    - 디지털 클론
        - 사람의 사고 능력, 취미, 취향을 디지털 세계에 재현
        - 이미지에서 표정을 추측하고 감정에 대응할 수 있는 센싱 기술과 빅데이터 기술의 연결
        - 기술 발전 후 센싱 데이터와 인공지능 기술을 연결하여 인격 재현 시도 가능성
- 기술적 특이점과 인공지능의 윤리적 관점
    - 레이 커즈와일
        - The Age of Spiritual Machines
            - 자율 주행 차량 개발, 사람을 이기는 체스 인공지능 등장 예측(1999)
        - 특이점이 온다
            - 의식을 지닌 인공지능을 기반에 두고 2045년에는 인류의 역사를 바꿀 정도의 큰 기술적 발전인 기술적 특이점(Singularity)이 올 것으로 예측(2007)
        - 인공지능 기술이 크게 발전할 것으로 기대
    - 인공지능 연구가 현재의 머신러닝이나 딥러닝을 이용하는 시스템을 통해 대량의 정보에서 답을 찾아내는 방법을 구현한 수준에 머무르고 있으며, 아직은 사람의 조정이 필요한 상태
    - 의식을 지닌 인공지능의 탄생과 올바른 윤리 의식을 가질 수 있도록 하는 것이 인공지능 연구의 영원한 숙제

# 규칙 기반 모델

- 조건 분기 프로그램과 규칙 기반 시스템
    
    ![Untitled](인공지능(1)/Untitled%2014.png)
    
    - “사람의 지능이 하는 일을 기계가 한다”라는 관점에서 초기 인공지능은 조건 분기 프로그램을 포함한다
    - 초기 인공지능 프로그램은 조건 분기 프로그램으로 구현
    - 현재 조건 분기 프로그램은 다른 분야에서 응용하여 사용
        
        ![Untitled](인공지능(1)/Untitled%2015.png)
        
    - 규칙 기반 시스템
        - 규칙(조건)을 사용해 조건 분기 프로그램을 실행하는 시스템
        - 프로그램이나 알고리즘의 순서도에 사용하는 IF ~ THEN 형태로 표현
        - 규칙 기반 시스템을 만들기 전 순서도를 이용해 규칙을 설정
    - 규칙의 문법
        - 규칙은 두 부분으로 구성
            - IF 부분 = 전제 또는 조건
            - THEN 부분 = 결론 또는 행동
        - 하나의 규칙에는 AND나 OR 또는 둘을 조합한 여러 조건이 존재할 수 있음\
    - 규칙의 종류
        - 관계 : IF ‘연료탱크’가 비었다 THEN 차가 멈췄다
        - 추천 : IF 가을이다 AND 하늘이 흐리다 AND 일기예보는 보슬비다 THEN 조언은 ‘우산을 가지고 가라’이다
        - 지시 : IF 차가 멈췄다 AND ‘연료 탱크’가 비었다 THEN ‘차에 연료를 공급’ 한다
        - 전략 :
            - IF 차가 멈췄다 THEN ‘연료탱크를 확인’ 한다 1단계를 완료했다
            - IF 1단계를 완료했다 AND ‘연료탱크’가 가득찼다
            - THEN ‘배터리를 확인’ 한다 2단계를 완료했다
        - 휴리스틱 :
            - IF 시료는 액체이다 AND ‘시료의 ph’ < 6 AND ‘시료의 냄새’가 시큼하다
            - THEN ‘시료의 성분’은 아세트산’이다.
    - 규칙 기반 시스템 예 (게임)
        - NPC(Non Player Character) 제어
            - IF enemy visible and my health is very low
            - OR enemy’s weapon is much better then mine
            - THEN propose retreat
    - 규칙 기반 시스템 적용 사례
        - 비즈니스 로직에 대응하는 업무 규칙을 시스템에 직접 등록하여 새로운 규칙 적용 가능
        - 프로그램 코딩 시 프로그램 개발 부담 및 테스팅, 재설치 비용의 부담
        - 시간이 대폭 감소
        - 오류의 최소화
        - 신속한 시장 대응 가능
- 규칙 설계와 문제의 공식화
    - 조건 분기의 기반이 되는 규칙은 사람이 미리 결정
    - 정답을 모르는 미지의 문제는 규칙 기반으로 대응이 어려움
    - 규칙 설정 시 순서와 우선 순위를 고려
    - 문제의 공식화 : 규칙 설계 과정에서 문제와 해법을 명확히 하는
    - 순서를 고려해야 할 경우
        
        ![Untitled](인공지능(1)/Untitled%2016.png)
        
    - 우선 순위가 고려되어야 할 경우
        
        ![Untitled](인공지능(1)/Untitled%2017.png)
        
        ![Untitled](인공지능(1)/Untitled%2018.png)
        
    - 문제의 공식화
        
        ![Untitled](인공지능(1)/Untitled%2019.png)
        

# 의사 결정 트리

- 의사 결정 트리의 구축
    - 의사 결정 트리(Decision Tree)
        - 규칙을 바탕으로 그린 순서도로 구축한 이진 트리
        - 통계학에 기반
        - 데이터를 처리하거나 분석할 때 사용
        - 데이터를 분석하여 이들 사이에 존재하는 패턴을 예측 가능한 규칙들의 조합으로 표현
            
            ![Untitled](인공지능(1)/Untitled%2020.png)
            
    - 규칙을 파악하지 못한 경우
        - 통계학 기반 데이터 분석 실행을 통해 규칙을 발견할 수 있다
        - 의사 결정 트리를 통해 고려 가능
    - BMI 데이터 의사 결정 트리 예시
        
        ![Untitled](인공지능(1)/Untitled%2021.png)
        
    - 의사 결정 트리 종류
        - 회귀 트리(Regression Tree)
            - 출력 변수가 연속형
            - 예측된 결과로 특정 의미를 지니는 실수값을 출력
            - 예) 주택의 가격, 환자의 입원 기간
        - 분류 트리(Classification Tree)
            - 출력 변수가 범주형
            - 예측된 결과로 입력 데이터가 분류되는 클래스를 출력
    - 장점
        - 결과를 해석하고 이해하기 쉬움
        - 자료 가공이 불필요
        - 수치 자료와 범주 자료에 모두 적용 가능
        - 화이트 박스 모델 사용
            - 조건에 대한 설명이 쉬움
            - 신경망은 대표적인 블랙박스 모델
        - 안정적
            - 명제의 불완전성에도 정상 동작
        - 대규모 데이터셋에도 동작 가능
            - 방대한 데이터의 일반 컴퓨터로 합리적인 시간 내로 분석
    - 단점
        - 휴리스틱 기법이 포함되어 완벽한 결과를 얻기 어려움
        - 훈련 학습자가 일반화하지 못할 경우 복잡한 결정 트리 생성
        - 배타적 논리합, 패티리, 멀티플렉서 같은 문제 처리가 어려움
        - 레벨이 다른 결과 처리 시 많은 레벨을 갖는 결과로 치우칠 수 있음
        - 약간의 차이에 따라 트리의 모양이 결정
        - 데이터 특성에 따라 분류율이 떨어질 수 있음
    - 신용 자료에 대한 의사 결정 트리의 예
        
        ![Untitled](인공지능(1)/Untitled%2022.png)
        

# 지식 기반 모델

- 규칙이 늘거나 변하는 경우
    - 지식 기반 모델
        - 규칙 기반 모델을 이용하여 규칙을 변경하는 모델
    - 지식 기반 시스템
        - 전문가의 지식을 데이터베이스화하여 저장하고 이를 이용
        - 특정 문제를 해결하기 위하여 실세계의 지식을 컴퓨터를 이용하여 표현하고 이를 이용하는 시스템
    - 규칙이 변경되거나 증가될 경우
        - 규칙 변경 시 규칙을 일일이 수정하는 작업 필요
            - → 고비용, 저효율
        - 프로그램과 데이터를 분리하여 처리
        - 분리된 데이터 → 지식 기반
    - 규칙이 고정적인 경우
        - 규칙을 변경하기 위해 프로그램을 수정 하는 것이 어려움
        - 초기에 프로그래밍 방향이 중요
        - 조건 설정 변경 시 프로그램 변경 작업이 쉬울 경우 문제 없음
        - 일반적으로 프로그램을 수정하는 것보다 다시 프로그래밍 하는 것이 효율적일 수 있음
            
            ![Untitled](인공지능(1)/Untitled%2023.png)
            
    - 규칙이 늘거나 변하는 경우
        - 조건 설정 데이터 셋과 실제 데이터 셋을 처리하는 프로그램을 분리
            - 지식 기반 (Knowledge Base)
                - 분리된 조건 설정 데이터 셋
                - 파일 시스템 또는 DBMS(Data Base Management System; 데이터베이스 관리 시스템)을 활용
                - 텍스트 편집기, GUI 형태의 제어판, 쿼리 언어 등을 이용한 시스템 활용
            - 프로그램은 조건 분기가 필요할 때 지식 기반에 저장된 ID를 사용해 설정 값을 읽고 판단하여 실제 데이터 셋을 처리
                
                ![Untitled](인공지능(1)/Untitled%2024.png)
                
- 사람도 검색할 수 있는 지식 기반 시스템
    - 지식 기반에 저장된 데이터는 많은 양의 데이터를 저장
    - 프로그램에서 지식 기반을 사용할 수도 있지만 전문적인 지식을 갖지 못한 사람들도 활용
    - 지식 기반 시스템(Knowledge Base System; KBS)
        - 절차적인 처리 보다 사람의 경험적 처리에 우선
        - 지식 기반 시스템에서의 검색은 특정 문제에 한정될 수 있음
        - 범용적 문제 처리를 위해서는 사람의 경험적 처리가 효율적
        - 고도의 특화된 도메인 지식(전문가의 지식)이 필요
        - 지식 기반 + 추론 엔진
            
            ![Untitled](인공지능(1)/Untitled%2025.png)
            
- UniProtKB
    - 유럽 생명 과학 분야 기관들이 협력해서 만든 지식 기반 데이터베이스 시스템
    - 단백질 정보 수집 후 주석 처리
        - 전 세계 주요 데이터베이스에 등록된 유전자 염기 서열과 아미노산 서열 수집
    - 큐레이션을 통해 UniProt Catalog 데이터베이스와 분석 도구 등을 개발
        - 단백질을 구성하는 아미노산 서열과 단백질 특성에 초점을 맞춘 정보 공개
            
            ![Untitled](인공지능(1)/Untitled%2026.png)
            

# 전문가 시스템

- 전문가 시스템
    - 규칙 기반 모델을 이용하는 추천 엔진에 기반
    - 현재까지 분석 결과 제공 시스템의 대부분은 전문가 시스템에 기반
    - 전문가 시스템이란?
        - 규칙 기반 시스템 중 전문가가 직접 하는 분류 또는 결정과 같은 판단 규칙에 도움을 주거나 대체할 수 있는 시스템
        - 특정 문제 영역에 관한 전문 지식을 지식 베이스에 저장하고 해당 문제 영역에 관한 다양한 문제를 해결하는 시스템
        - 생성 시스템의 하나
        - 의료 진단 시스템 또는 설계 시스템 등
            
            ![Untitled](인공지능(1)/Untitled%2027.png)
            
- 초기 전문가 시스템 Dendral
    - 1965년 스탠퍼드 대학에서 시작된 프로젝트
    - 물질의 질량 분석 후 분자량을 얻어 이를 해당 물질의 화학 구조 파악 시 이용
    - LISP 사용
    - 예시
        - 물의 분자량은 H = 1, O = 16이므로 정수값으로 18이 됨
        - 질량 분석 시 18 근처에서 피크값을 얻음
        - 에탄올(C2H5OH)는 C = 12, H = 1, O = 16으로 정수값 46이 되어 질량 분석 시 46 근처에서 피크 값을 얻음
        - 질량 분석을 통해 얻은 피크 값을 통해 역으로 화학 구조를 파악
        - 분자량 증가 시 원자 조합이 다양해 지며 시간이 오래 걸릴 수 있음
    - Dendral 구성
        - Heuristic-Dendral
            - 전문가의 경험적 분석을 실행
        - Meta-Dendral(학습 시스템)
            - 분자 결합 구조와 질량 스펙트럼 셋을 지식 기반에 저장하고 Heuristic-Dendral에 피드백
    - 물의 경우 18 근처에서 피크 값을 얻을 수 있음
    - 에탄올은 다양한 분포를 보이나 46 근처에서 피크 값을 얻을 수 있음
        
        ![Untitled](인공지능(1)/Untitled%2028.png)
        
- Dendral에서 파생된 MYCIN
    - 1970년대에 구축
    - 항생제의 접미사인 ‘~mycin’에서 유래
    - 환자의 전염성 혈액 진단 후 항생제, 투약량 등 제시
    - 500개 정도의 규칙을 통해 판정
    - 이진 규칙 외에도 답변 형식을 요구하는 질문도 존재
    - 결과의 신뢰도 순서에 따라 질환 원인 표시 및 치료 과정 제안
    - 세균 감염 전문의가 아닌 의사보다 높은 진단율을 보이지만 전문의 보다는 낮은 정답 신뢰도를 나타냄
    - 윤리적, 법률적 책임 문제로 실제 현장 사용 사례가 없음
    - 의료 전문가 시스템의 경우 진단 정답율 85~90% 이상, 거짓 양성과 거짓 음성이 적어야 함

# 추론 엔진의 종류와 기법

- 전문가 시스템이 규칙을 사용해 결과를 추론하는 프로그램
    - 추론 엔진의 규칙은 명제 논리, 술어 논리, 인식 논리, 퍼지 논리 등의 수리논리학을 이용
        - 명제 논리 : 가장 기본적으로 사용하는 수리 논리학
        - 논리 연산자를 이용하여 명제 사이의 관련성 표현
        - 술어 논리 등을 이용해 의미 부여 시 추론 엔진으로 동작 가능한 논리 구성이 된다.
            
            ![Untitled](인공지능(1)/Untitled%2029.png)
            
- 명제 논리의 기호 종류
    - 명제 변수와 논리 연산자로 구성
        
        ![Untitled](인공지능(1)/Untitled%2030.png)
        
        ![Untitled](인공지능(1)/Untitled%2031.png)
        
- 술어 논리의 기호 종류
    - 논리식에 기호를 조합해 논리 표현의 폭을 넓힘
    
    ![Untitled](인공지능(1)/Untitled%2032.png)
    
    ![Untitled](인공지능(1)/Untitled%2033.png)
    
    ![Untitled](인공지능(1)/Untitled%2034.png)
    
- 진리표
    
    ![Untitled](인공지능(1)/Untitled%2035.png)
    
- 논리식의 주 동치 관계
    
    ![Untitled](인공지능(1)/Untitled%2036.png)
    
- 논리곱 표준형과 스콜렘 표준형
    - 논리곱 표준형(Conjunctive normal form; CNF)
        - 명제 논리식을 절 형식(Clause form)으로 변환하는 것
        - 선언적으로 결합한 논리식
        - 이중부정, 드모르간, 분배 법칙을 사용하여 변환
    - 스콜렘 표준형
        - 술어 논리식을 절 형식으로 변환하는 것
        - 스콜렘 함수로 존재 기호(∋)를 제거하도록 변환

# 추천 엔진

- 추천 엔진의 개념
    - 빠른 정보를 추측해서 제시하는 전문가 시스템
    - 특히 쇼핑몰 사이트나 언론사에서 사용하는 경우가 많음
    - 간단한 예로 다양한 정보에서 연관성 있는 정보 찾기
    - 협업 필터링을 이용해 사용자화 추천하기
        - 예)
            - 온라인 쇼핑몰의 제품 추천
            - 흥미로운 웹사이트 추천
            - 음악과 영화 검색 도우미 등
    - 추천엔진의 예
        - 쇼핑몰 방문자에게 “이 상품을 본 후에 구매한 상품은?” 같은 질문을 통한 추천 정보 제공
        - 쇼핑몰 등의 사이트 방문자에게 비슷한 정보를 추천하는 시스템과 같이 전문가 시스템의 한 예
    - 전문가 시스템으로 구현하면
        - “방문자가 보는 정보를 키워드로 비슷한 정보를 표시하라”는 질문 실행과 동일
    - 추천 엔진 방법
        - 콘텐츠 내용에서 비슷한 정보를 찾아 정보 추천
        - 방문자의 검색 이력 또는 구매 이력 등 사이트 방문자 고유 정보를 이용해 연관 정보 추천
            
            ![Untitled](인공지능(1)/Untitled%2037.png)
            
- 콘텐츠 내용을 분석하는 추천 엔진
    - 사이트 사용자 및 방문자의 정보를 제외한 콘텐츠 자체의 정보에서 관련 있는 내용 검색 후 추천
        - 콘텐츠 정보의 예
            - 쇼핑몰의 상품 정보, 뉴스 사이트의 기사 정보 등
    - 지식 기반에 저장 가능한 콘텐츠(Feature; 특징량)
        - 정보 구성 요소 : 제목, 장르 등
        - 계산을 통해 찾는 데이터
            - 기사 추천의 예
                - 지진 뉴스를 보는 A에게 다음은 어떤 기사를 추천할 것인가?
                    - —> 키워드를 통한 관련성 정의
                        
                        ![Untitled](인공지능(1)/Untitled%2038.png)
                        
- 협업 필터링을 이용하는 추천 엔진
    - 협업 필터링
        - 많은 사용자들로부터 얻은 기호 정보(Taste information) 에 따라 사용자들의 관심사들을 자동으로 예측하게 해 주는 방법
        - 정보 과잉 문제를 해결하기 위한 정보 필터링의 주요 기법
        - 큰 무리의 사람들을 검색해서 유사한 취향을 갖는 작은 집합을 발견하는 방법
        - 능동적 필터링
            - P2P 방식
            - 사람들이 다른 비슷한 집단의 사람들이 구매한 물건의 정보를 공유하고자 한다는 사실에 기초
        - 수동적 필터링
            - 특정 집단의 정보가 아닌 일반 집단의 정보를 사용
    - 협업 알고리즘
        - 방문자 또는 사용자의 고유 데이터를 이용하여 적합한 무엇인가를 추천하는 경우 많이 사용되는 알고리즘
            - 대표적인 예 : 아마존의 아이템 기반의 협업 필터링
        - 콘텐츠 분석 추천 엔진에 사용자 고유 데이터를 결합하여 상관 분석
    - 협업 필터링 예시
        - 상품 구매 의지를 가진 X와 그렇지 않은 A ~ E가 있을 경우 각 사용자의 구매 이력을 조회하여 추천도와 상관 계수를 산출
            
            ![Untitled](인공지능(1)/Untitled%2039.png)
            
            - 위 표를 기준으로 X와 다른 방문자 간의 상관 계수를 피어슨 상관 계수 공식으로 산출
    - X와 A의 피어슨 상관 계수 산출 예시
        
        ![Untitled](인공지능(1)/Untitled%2040.png)
        
    - X와 A ~ E의 상관계수를 산출한 결과
        - 산출 결과 계수 값이 0.5 이상으로 X와 같은 구매 경향이 있는 사람은 C, D, E로 판별
            
            ![Untitled](인공지능(1)/Untitled%2041.png)
            
    - 최종적으로 X와 관련이 없는 상품 (1, 4, 5, 6, 7) 을 대상으로 C, D, E의 구매 기록을 통해 X가 살 가능성이 있는 상품을 계산
        
        ![Untitled](인공지능(1)/Untitled%2042.png)
        
        - 가장 높은 추천 정도를 받은 상품 5가 X에게 추천
        - 보통 5단계의 값을 사용

# 인간지능과 인공지능

- 인간의 두뇌
    
    ![Untitled](인공지능(1)/Untitled%2043.png)
    
    - 인간 두뇌
        - 인간 두뇌에는 약 140억 개 정도의 뉴런이 있음
        - 뉴런의 작동 원리는 현재로서는 자세히 알기 어려움
        - 지금까지 어느 정도 규명된 것은 뉴런의 구조 뿐
        - 성인의 두뇌 뉴런 개수와 신생아의 뉴런 개수는 동일
        - 뉴런은 태어난 이후 수가 늘지 않으며 재생 불가
        - 인간은 20세 이후 매일 수만 개의 뉴런이 죽어감
        - 머리를 많이 쓸수록 후천적으로 두뇌 발달
        - 인간 두뇌의 구현이 신경망이나 인공지능 연구의 목표
    - 인간 두뇌의 연구
        
        ![Untitled](인공지능(1)/Untitled%2044.png)
        
        - 두뇌의 특정 부분에서의 작용들은 상당 부분 판명됨
        - 두뇌 작용은 뉴런들의 호르몬이나 전기적인 작동으로 추정
        - 연구가 진전되면 인간의 감정이나 의식과 같은 연구도 가능할 것
    - 인간 두뇌는 좌뇌와 우뇌로 구분
        - 좌뇌
            - 규칙이나 논리의 순차적 정보처리 위주
            - 규칙기반 인공지능과 연관이 많음
            - 합리적, 분석적, 계수적 논리 사고 담당
            - 계산 능력, 분석 능력, 논리적 추리 등
        - 우뇌
            - 예술적, 추상적 사고 등의 병렬 정보 처리
            - 패턴인식, 기하학적인 정보처리와 관련이 많음
            - 학습에 적합한 신경망과 관련이 많음
    - 좌뇌와 우뇌의 정보는 ‘뇌량’을 통해 종합적으로 판단됨
- 인간의 지능과 인공지능
    - 지능(intelligence)이 가지는 주요 능력들
        - 학습하고 논리적으로 추론하는 능력
        - 패턴을 인식하고 주어진 상황을 해석하는 능력
        - 상황을 단순화시켜 문제의 본질 분석 능력
        - 다양하게 만나는 문제들의 해결 능력
    - 인간 두뇌의 능력
        - 빠르고 정확한 계산 능력
        - 이전에 일어난 수많은 일들을 기억하는 능력
        - 빠르고 정확하게 추론해내는 능력
        - 도형의 특성을 이해하고 인식하는 공간 지각 능력
        - 물체와 문자를 인식하고 이해할 수 있는 능력
        - 꿈꾸듯 상상하는 상상력
        - 기억력, 계산력 등에 해당하는 인공지능은 많이 발전하여 컴퓨터로도 인간보다 빠르고 정확
        - 추리력 면에서도 LISP이라는 프로그래밍 언어를 사용하면 빠르고 정확
    - 인간 두뇌 능력과 인공지능의 차이
        - 상상력, 직관력, 이해력, 공간 능력, 연상 능력 등
        - 인공지능의 창의성은 상상력과 직관력 등에서 제한됨
    - 상상력 : 상상의 날개를 펴는 능력
    - 직관력 : 마치 ‘척 보면 아는 듯한’ 능력
    - 이해력 : 사리를 분별하여 해석하는 힘
    - 공간 능력 : 물체를 인식할 수 있는 능력
    - 연상 능력 : 일부 정보로 나머지를 연상해내는 능력
- 인간의 지능지수
    - 인간의 지능은 다양한 능력들을 종합적으로 평가
    - 지능 평가 기준은 지능지수(intelligence Quotient: IQ) 사용
    - IQ는 정신연령을 실제 생활연령으로 나누어 100을 곱한 수
        
        ![Untitled](인공지능(1)/Untitled%2045.png)
        
    - IQ는 평균 100을 기준으로 정규 분포
    - 지능지수와 학업 성적이 비례하는 것은 아님

# 인공지능에 사용되는 수학적 배경

- 인공지능과 수학
    - 수학은 일반적인 현상들을 상징적인 기호로 표현하여 그 관계를 규명하는 것
    - 수준 높은 인공지능 탐구를 위해 수학적 바탕 필요
    - 인공지능 관련 유명 인물 중 수학 관련 사람이 많음
        - 앨런 튜링과 민스키 등도 수학자 출신
    - 인공지능은 수학적 모델링과 관계가 깊음
        - 인간의 지능적인 행위를 수학적인 방정식과 적절하게 매치 시키는 방법을 고안 필요
- 인공지능 연구에 필요한 수학적 기초
    - 일반인들에게 교양 수준으로의 인공지능은 인공지능의 개념, 간략한 원리, 응용 정도면 충분
    - 인공지능 연구개발 예정자는 기초적인 수학 지식이 필요
        - 행렬과 벡터는 매우 필요한 핵심적인 수학 개념
            - 행렬 : 데이터의 공간 변환 등에서 필수적인 도구
        - 인공 지능의 최적 설계에도 수학적 개념이 필요
        - 확률의 추출 과정에서 필수적인 도구
- 인공지능 연구에 필요한 수학적 지식의 예
    - 함수의 개념
        - 시그모이드(sigmoid) 함수는 신경망 출력 함수
        - 시그모이드 함수는 로지스틱 함수의 특별한 경우
        - 시그모이드 함수의 경우는 비선형 함수로 복잡한 데이터를 표현하는데 우수
            
            ![Untitled](인공지능(1)/Untitled%2046.png)
            
    - 선형 회귀
        - 한 반의 학생들의 앉은 키와 선 키와의 연관성을 구해 보자
            - 한 반에 있는 학생들의 앉은 키는, 이 학생들의 키가 커진다면 그만큼 비슷하게 커질 것이다. 따라서 한 반에 있는 학생들의 앉은키와 그냥 키, 두 가지 값을 잘 계산한다면 직선의 방정식 y=ax+b 꼴로 앉은키와 그냥 키의 관계식을 만들어낼 수 있다.
    - 미분 개념
        - 인공지능의 최적화 과정에서 미분 개념이 사용
        - 미분은 신경망 학습에 필요한 기초 지식
        - 델타 규칙과 연전파 알고리즘 등의 적용에 필요
        - 신경망 학습에서 체인(chain) 규칙 사용
            
            ![Untitled](인공지능(1)/Untitled%2047.png)
            
            ![Untitled](인공지능(1)/Untitled%2048.png)
            
    - 벡터(vector)와 관련된 기초 지식과 개념 이해가 중요
        - 벡터는 신경망의 입력으로 들어갈 데이터 사용에 필요
        - 벡터의 내적과 벡터들 사이의 거리 측정 방법
        - 선형 변환 등의 지식이 필요
            
            ![Untitled](인공지능(1)/Untitled%2049.png)
            
    - 행렬(matrix)과 행렬식(determinant)에 관한 기본 지식이 요구
        - 행렬의 곱셈과 선형 변환 등과 관련된 지식이 필요
        - 신경망에서는 행렬의 곱셈이 기본적으로 사용됨
        - 데이터의 표현을 행렬로 나타내는 경우가 많음
        - 주어진 입력과 연결 강도를 곱할 때의 행렬 연산에 필요
            
            ![Untitled](인공지능(1)/Untitled%2050.png)
            
    - 통계와 확률, 그리고 회귀 분석
        - 인공지능의 최종 결과물은 확률로 표시될 수도 있음
        - 통계에서 평균, 분산, 표준편차, 상관 계수 등 지식 필요
        - 확률에 관한 지식이 필요
        - 머신러닝에서 분류를 위한 회귀 분석에 대한 기초
        - 선형 회귀, K-mean, K-NN 분류 등의 기반 지식
            
            ![Untitled](인공지능(1)/Untitled%2051.png)
            
    - 신경망과 심층신경망의 구현
        - 경사하강법, 역전파 알고리즘, 임계값, 선형 함수 등의 함수에 대한 지식
        - 이산수학(discreate mathematics)에 관한 지식
        - 영상인식이나 음성인식을 위한 기본 지식
            
            ![Untitled](인공지능(1)/Untitled%2052.png)
            

# 인공지능 구현을 위한 프로그래밍 언어

- 인공지능용 프로그래밍 언어
    - 프로그래밍 언어(Programming Languages : PL)
        - 인간과 컴퓨터 사이의 의사 소통용 인공적인 언어
        - 인공지능의 초기 응용 분야에는 LISP 많이 사용
        - 논리를 처리하는데 편리한 Prolog도 많이 이용
        - 현재 신경망이나 딥러닝의 경우 Python이 많이 이용
    - LISP
        
        ![Untitled](인공지능(1)/Untitled%2053.png)
        
        - Lisp Processing의 약자
        - 1960년 매카시에 의해 개발되어 지금도 활용되고 있음
        - LISP 은 기호 형태의 자료형을 주로 쉽게 처리
        - 리스트(list)와 트리(tree) 형태로 자료 구조 처리
        - 주요 특징
            - 대화식으로 구성된 인터프리터 방식의 언어
            - 괄호를 사용하는 고급 프로그래밍 언어
            - 프로그램과 자료가 같은 형태로 취급됨
            - 소프트웨어들이 LISP 으로 많이 개발되어 있어 활용도가 높음
    - Prolog
        
        ![Untitled](인공지능(1)/Untitled%2054.png)
        
        - 주요 특징
            - 사실(fact), 규칙(rule), 질문(question)들로 구성
            - 인터프리터 언어이며 대화식의 명령 방식으로 작동
            - 사실과 규칙들의 데이터베이스로 구성됨
            - 질문에 응답하는 형식으로 진행
            - 추론 엔진(inference engine)을 사용
    - Python, R, C 등
        
        ![Untitled](인공지능(1)/Untitled%2055.png)
        
        - 최근 Python이 인기 있는 프로그래밍 언어로 주목 받기 시작
        - 특히 코딩의 중요성이 강조되면서 사용자가 늘어나고 있음
        - 문법이 비교적 간단하여 빠르고 쉽게 배울 수 있음
        - 인터프리터 언어로서 실행 결과를 즉석에서 확인할 수 있음
        - C언어는 범용 언어로 인공지능에서도 쓰이고 있음
        - 그 외 R 언어 등이 인공지능에 사용되고 있음
        

# 문제 해결

- 인공지능과 문제 해결
    - 문제
        - 우리가 살아가면서 만나는 다양한 문제(problem)들을 해결
        - 인공지능이 발전하더라도 인간이 해결해야 할 일도 많음
            - 인공지능이 하나의 하드웨어가 되고 인간은 소프트웨어로써 인공지능을 활용
            - 인간의 생각과 사고가 없다면 인공지능도 큰 역할을 수행하지 못함
        - 인공지능 시대에서 문제 해결에 관한 논제는 매우 중요
        - 어떤 방법으로 문제를 해결할지에 대한 깊은 사고력 필요
    - 문제 해결에 도움이 되는 사고
        - (basics) 기본 개념과 원리를 생각하며 문제에 적용
        - (similarity) 비슷한 유형의 문제는 같은 방법으로 적용
        - (abstraction) 어렵게 보이는 문제를 단순화시킬 수 있는지를 점검
        - (decomposition) 복잡한 문제는 여러 단계로 나누어 문제 해결
        - (multiformity) 다양한 관점으로 문제의 핵심에 접근
        - (creativity) 자유로운 생각으로 문제 해결의 실마리를 끌어냄
    - 인공지능 시대의 문제 해결 전략
        - 컴퓨터를 이용하여 문제 해결이 가능한 방안 마련
        - 블록 다이어그램을 그려 문제를 단계별로 분석
        - 규칙을 찾아 규칙기반 인공지능에 적용 여부 고려
        - 신경망이나 딥러닝의 인식 기능 활용
        - 데이터 사이언스나 빅데이터를 적용할 수 있는지 검토
        - 인간의 사고와 컴퓨터 능력을 통합한 컴퓨팅 사고 적용
- 문제 해결의 핵심인 사고의 힘
    - 사고력
        - 인간 사고 능력의 결과물은 지식
        - 지식을 오랜 기간 문자를 통해 후대로 전달
        - 연산의 필요로 컴퓨터가 발명
            - 인간처럼 사고할 수 있는 인공지능에 도전
            - 인공지능의 발전에도 불구하고 인간의 사고력은 중요한 역할
- 인공지능 시대의 컴퓨팅 사고
    - 컴퓨팅 사고
        - 인공지능 시대에는 새로운 사고 방법 필요
            - 단순한 방식의 문제 해결과 맹목적인 코딩이 불필요
            - 컴퓨팅 사고(computational thinking) 대두
            - 컴퓨터를 활용하여 문제 해결을 위해 사고하는 방법
            - 기존의 인간 사고와는 달리 컴퓨터를 활용하여 문제를 해결하는 과정에서 여러 가지 특성을 포함하는 문제 해결 과정
        - 지넷 윙(Wing) 교수 주장
            - 컴퓨팅 사고는 누구에게나 일반적으로 적용되는 사고 방식과 기술의 집합인데, 배우고 익혀서 사용할 가치가 충분
        - 인간의 사고 능력과 컴퓨터의 능력을 통합한 사고
        - 복합적 사고를 통해 창의적으로 문제를 해결하는 능력
        - 복잡한 문제의 해결에 상당히 효율적인 결과 보여줌
        - 복잡한 것을 자신감 있게 다루는 능력 향상
        - 어려운 문제들을 지속적으로 다루는 능력 향상
        - 다양한 해답이 있을 수 있는 문제를 다루는 능력 향상
    - 컴퓨팅 사고에서 고려해야 할 주요 사항들
        - 문제 해결의 결과 정확한 답을 얻을 수 있는가?
        - 가장 효율적인 문제 해결 방법인가?
        - 가장 빠르고 논리적인 문제 해결 방법인가?
        - 다른 문제들을 해결하는데도 쓰일 수 있는가?
    - 컴퓨팅 사고의 발상
        - 컴퓨팅 사고는 컴퓨팅 능력 + 깊은 사고력의 융합
        - 문제를 효율적으로 해결하기 위한 방법
        - 문제 분석, 분해, 패턴 찾아내기, 추상화 단계를 거쳐 알고리즘으로 연결
        - 프로그래밍을 통해 컴퓨터를 작동시켜 자동화 구현
        - 컴퓨팅 사고의 발상
            - 컴퓨팅 능력(Power of computing) + 깊은 사고력(Critical thinking) = 컴퓨팅 사고(Computational thinking)
- 문제 해결을 위한 컴퓨팅 사고
    - 문제 해결을 위한 컴퓨팅 사고의 4대 요소
        - 분해, 패턴인식, 추상화, 그리고 알고리즘 단계
        - 이 4가지 요소들을 정확하게 활용하는 기술
        - 컴퓨팅 사고의 4대 요소
            - 분해(Decomposition)
            - 패턴 인식(Pattern Recognition)
            - 추상화(Abstraction)
            - 알고리즘(Algorithm)
    - 컴퓨팅 사고의 4단계
        - 분해
            - 어려운 문제를 작은 단위의 쉬운 문제로 나누어 해결할 수 있는 사고
            - 복잡한 난이도의 감소를 유도
        - 패턴인식
            - 규칙성과 패턴들을 발견, 유사성 찾아내기
            - 문제를 효율적으로 해결하기 위함
        - 추상화
            - 복잡한 문제의 핵심을 파악할 수 있는 사고
            - 문제 내 필요한 부분과 필요하지 않은 부분을 분리하여 집중하는 것
        - 알고리즘
            - 문제들을 해결할 수 있는 일련의 논리적인 지시
            - 문제에 대한 단계적인 해결책이나 설명, 지시 사항들을 설계
- 컴퓨팅 사고의 장점
    - 문제 해결 능력 배양
    - 일반적인 지식은 필요한 분야에만 사용이 한정되는 경우가 많음
    - 컴퓨팅 사고에서는 사고의 틀(template)을 여러 분야에 적용 가능
        - 컴퓨팅 사고의 틀을 익히면 여러 분야에 활용 가능
        - 컴퓨터 분야의 컨텐츠 개발 및 다양한 공학 분야나 문학 등 인문 분야에도 문제 해결 과정에 큰 도움
    - 지식의 효율적 활용 및 인공지능 기술과의 융합 기대
    - 컴퓨팅 사고를 통한 문제 해결의 예
        - ‘서울버스’ 앱
            - 무작정 버스를 기다리는 불편함 해소
            - 컴퓨팅 사고의 방법을 잘 적용
                - 버스의 출발 시간, 주행 시간, 대기 시간 등의 자료를 수집하고 분석
                - 복잡함을 단순하게 만들고 컴퓨팅 사고의 과정을 거쳐 적용
            - 버스 이용객에게 많은 사랑을 받고 있음
        - 심야 버스 노선 신설
            - 사람들이 심야에 택시를 많이 호출하는 지역에 심야 노선 버스를 신설
            - 원인 파악에서 해결 방안으로 컴퓨팅 사고를 접목
                - 심야 시간 택시 호출을 위한 전화 통화량 수집
                - 심야 택시의 이동 경로 수집

# 현대의 코딩

- 코딩을 통한 인공지능 접근
    - 컴퓨팅 사고의 영향으로 직접 프로그래밍을 하는 코딩이 주목
    - 코딩으로 만들어지는 앱(App) 또는 어플리케이션에 대한 기초적인 지식 필요
    - 코딩
        - 컴퓨터 프로그램을 수행하는 절차를 적어둔 명령어들인 코드(code)를 작성하는 행위
        - 실행 가능한 프로그램을 작성하는 일
    - 알고리즘
        - 코딩을 위해 명령어들을 순서대로 나열하는 작업
        - 논리적이고 효율적이어야 함
    - 코딩의 목표
        - 주어진 문제를 제대로 해결하는 일                                  (문제해결)
        - 코딩하기 전에 문제 해결을 위한 방법부터 먼저 구상 (알고리즘)
        - 코딩을 마치고 컴퓨터를 작동시켜 문제 해결                (자동화)
            
            ![Untitled](인공지능(1)/Untitled%2056.png)
            
    - 인공지능 문제에 대한 코딩
        - 현재 인공지능의 주 관심사는 기계학습과 딥러닝, 인식 등
        - 기계 학습을 위해 필요한 빅데이터를 처리하기 위해 자동화된 시스템 필요
        - 학습 목적에 맞는 자동화된 시스템을 개발하기 위해 코딩이 접목
        - 형식적 언어가 아닌 즉시 응답을 받을 수 있는 스크립트 형 언어들이 주목
            - 파이선이나 R과 같은 언어들은 쉬운 문법과 다양한 기능 활용 가능
            - 데이터 수집부터 분석, 처리, 표현까지 다양한 활용이 가능
            - 누구나 쉽게 배우고 목적에 맞는 학습 알고리즘의 개발이 가능
            - 코딩에 필요한 기본적인 개념과 활용 능력을 학습하여 다양하게 활용 가능
- 코딩의 중요성
    - 빌 게이츠(Bill Gates)
        - 13살 때 처음으로 코딩하는 방법을 배웠고, 이를 바탕으로 마이크로소프트를 세웠다
    - 미국 오바마(Obama) 전 대통령
        - 코딩 기술을 배우는 것이 여러분의 미래는 물론 조국의 미래에도 매우 중요하다
    - 스티브 잡스(Steve Jobs)
        - 이 나라 모든 사람들은 컴퓨터 프로그래밍 즉 코딩을 배워야 한다. 코딩은 생각하는 방법을 가르쳐주기 때문이다.
    - 디지털 시대에 필요한 컴퓨팅적 사고력을 키우는 교육 도구
    - 현재는 4차 산업 시대이며 4차 산업 시대의 핵심 요소는 “융합”
    - 융합 시대에 산업과 산업을 융합 시킬 수 있는 연결 고리가 코딩이 될 수 있음
    - 4차 산업 시대의 인공지능과 코딩
        - 소프트웨어 전공자들에게만 필요한 코딩이 아닌 다른 분야의 전공자들에게도 필요
        - 개발자 코딩 교육과 사용자 코딩 교육은 구분되어야 함
        - 인공지능을 이용한 소프트웨어 개발도 가능하게 된 시대에 모든 학생들이 개발을 위한 코딩 교육을 받을 필요는 없음
        - 단지 컴퓨팅 사고를 통한 문제 해결 능력을 키워 4차 산업 시대의 인공지능을 활용하는 방식으로 변화가 필요
- 코딩의 주요 목적
    - 인공지능 시대에는 코딩이 기초적이고 필수적인 요소
    - 코딩 과정을 통해 논리적 사고력 향상
    - 문제 해결을 위한 생각하는 힘을 기를 수 있는 장점
    - 코딩을 함으로써 창의적 발상과 지구력 향상
    - 컴퓨팅 사고로 미래 직업에 대한 효율적인 대응 전략
- 코딩의 종류
    - 스크래치(scracth)
        - 2007년 미국 MIT에서 개발된 무료 소프트웨어
        - 프로그래밍 초보자용 시각적 교육용 프로그래밍 언어
        - 여러 가지 모양과 색깔의 코드 블록들을 끌어다가 조합하는 블록형 프로그래밍
        - 캐릭터가 춤을 추게 하거나 스토리를 만들 수 있음
        - 게임, 애니메이션, 음악, 미술, 대화형 스토리텔링 등 구현
        - 누구나 컴퓨터 프로그래밍의 개념을 쉽게 배울 수 있음
    - 아두이노(Arduino)
        - 마이크로 보드와 같은 하드웨어를 조절하는 코딩 도구의 예
        - 아두이노는 다양한 제작물을 만드는 개방형 프로그램
        - 아두이노 활용 예
            - 키보드나 마우스로 조종하는 움직이는 자동차 로봇 구현
            - IoT 센서를 활용한 기기 제어
            - 블루투스 등을 활용한 무선 통신 기술 접목
    - Python
        - 1991년 귀도 로섬이 발표한 프로그래밍 언어
        - 누구나 www.python.org에서 무료로 다운받아 사용 가능한 오픈 소스
        - C, Java, 그리고 LISP의 특징들을 모두 가지고 있음
        - 인공지능의 확산으로 인기 있는 프로그래밍 언어
        - 최근 사용자가 꾸준히 늘고 있는 추세
        - Python의 주요 특징 요약
            - 인터프리터 언어로서 실행 결과를 즉석에서 확인할 수 있는 스크립트 언어
            - 다른 언어에 비해 문법이 비교적 간단
            - ‘들여쓰기’로 블록을 구분하는 독특한 문법을 채용
            - 포인터 개념이 없음
            - 신경망과 딥러닝 코딩에 많이 쓰임
            - 텐서플로가 Python 응용 프로그래밍 인터페이스(API) 제공

# 인공지능 코딩의 경험

- 인공지능 코딩의 사용 예
    - 규칙 기반 문제 해결을 위한 코딩
        - 데이터베이스에 규칙을 설정
        - 문제가 주어지면 문제에서 규칙을 적용할 키워드를 추출
        - 키워드에 해당하는 규칙을 데이터베이스에서 검색하여 결과 도축
        - LISP의 예
            
            ![Untitled](인공지능(1)/Untitled%2057.png)
            
        - Prolog의 예
            
            ![Untitled](인공지능(1)/Untitled%2058.png)
            
    - 확률 기반 문제 해결을 위한 코딩
        - 사전에 발생하는 사건들에 대한 확률을 계산
        - 문제가 주어지면 문제에서 발생하는 사건들을 확률과 통계를 산출
        - 문제 해결에 필요한 확률 값을 계산하여 결론 도출
        - 나이브 베이즈 분류기 예
            
            ![Untitled](인공지능(1)/Untitled%2059.png)
            
            ![Untitled](인공지능(1)/Untitled%2060.png)
            
        - GMM(가우시안 혼합 모델)
            - 문서의 주제에 따른 분류
            - 퍼지 영상 분할(Fuzzy image segmentation)
    - 분류, 회귀와 같은 기계 학습 문제 해결을 위한 코딩
        - 주어진 문제의 도메인에서 목적에 따른 타겟 값을 구분하여 데이터베이스에 저장
        - 문제가 주어지면 해당하는 타겟 값을 계산 식에 의한 산출
        - 나이와 몸무게의 추정 예
            
            ![Untitled](인공지능(1)/Untitled%2061.png)
            
            ![Untitled](인공지능(1)/Untitled%2062.png)
            

# 선형 문제와 비선형 문제

- 두 변수의 상관 관계
    - 다수의 데이터에서 예측과 분석을 수행할 때
        - 수학적 모델과 통계 모델을 검토
        - 임의의 2개의 데이터를 비교
        - 수집한 데이터가 어떻게 변하는지 확인한 후 앞으로 수집할 데이터의 변화를 비교, 예측
    - 변수
        - 데이터를 다룰 때 데이터를 구성하는 항목
    - 특징량 (Feature)
        - 데이터에서 변화를 나타내는 한 가지 이상의 변수 쌍, 또는 변수 쌍을 사용한 계산
        
        ![Untitled](인공지능(1)/Untitled%2063.png)
        
- 선형 계획법과 비선형 계획법
    - 선형 계획법
        - 선형 함수
            - 변수값 쌍을 그래프에 점으로 표현했을 때 일직선처럼 보일 경우
        - 선형 계획 문제
            - 점의 분포를 선형 함수의 제약과 조건을 이용해 구할 수 있는 문제(예: 배낭 문제)
        - 정수 계획 문제
            - 선형 계획 문제 중 정수에 한정해서 문제를 해결할 때
        - 선형 함수를 최적화하여 문제를 해결하는 것
            
            ![Untitled](인공지능(1)/Untitled%2064.png)
            
        - 선형 계획법 실제 사례
            - 금융회사에서 포트폴리오 구성 시
                - 투자 대상과 예상 수익율을 변수로 구성
                - 투자 금액 및 투자 시 필요한 제약 조건 설정
                - 연간 예상 수익율을 최대화 하는 것을 목표로 목적 함수를 구성하여 분석 수행
            - 식당 종업원 수를 시간별로 조정하는 문제 시
                - 시간대 별 종업원 수를 변수로 구성
                - 시간대에 따른 종업원 수를 제약 조건으로 설정
                - 시간대 별 최적 종업원 수를 목표로 목적 함수로 구성하여 분석 수행
        - 사상
            - 변수값 쌍을 점 형태로 표현하여 함수 형태로 변환한 것
            - 단사 함수(일대 일 함수) : 점의 집합을 각각 A와 B라고 할 경우 A의 원소와 B의 원소가 1 : 1로 대응하는 경우
            - 전사 함수 : A가 B의 모든 원소에 대응하는 함수
            - 전단사 함수 : A와 B의 원소가 중복 없이 모두 1 : 1 로 대응하는 함수
            
            ![Untitled](인공지능(1)/Untitled%2065.png)
            
    - 비선형 계획법
        - 변수값 쌍으로 구성하는 점의 분포가 선형으로 표현되지 못할 경우
        - 선형 분리 불가능한 분포도
        - 비선형 분포 : 사상 개념으로 대응할 수 없을 경우
            
            ![Untitled](인공지능(1)/Untitled%2066.png)
            
        - 비선형 문제 : 비선형 분포를 다루는 문제
        - 비선형 계획법 실제 적용 예
            - 신제품 출시에 따른 가격 책정 문제
                - 신제품에 대한 가격 Price를 결정하기 위해 수요량을 예측해 볼 경우
                - 수요량 Demands는 Price에 따라 증가 또는 감소할 수 있는 종속 변수
                - 따라서 최종 목적 함수인 가격 결정은 신제품의 판매 이익과 원가에 의해 결정되며 판매 이익 및 원가는 수요에 따라 변동될 수 있음
                - 결국 최종 목적 함수가 2차 함수가 되어 선형 계획법으로 해결이 어려움
                - 2차 함수의 최대 또는 최소값 산출을 위해 각 변수에 따른 편미분을 이용하여 조건을 만족하는 결과 값 산출
        - 볼록 계획 문제
            - 볼록(凸) 함수 & 오목(凹)함수로 점의 분포를 나타낼 수 있는 경우에 사용
            - 볼록 최적화 방법을 이용해 해결
                
                ![Untitled](인공지능(1)/Untitled%2067.png)
                
                ![Untitled](인공지능(1)/Untitled%2068.png)
                
        - 볼록 함수
            - 볼록 집합 : 집합에 존재하는 그 어떤 점을 잡아도 그 점들 사이에 있는 모든 점들 역시 그 집합에 포함되는 집합
            - 최적 값이 한 개 밖에 존재하지 않음
            - 따라서 위로 볼록한 경우 최대값이 최적값이 되며, 아래로 볼록한 경우 최소값이 최적값이 됨
                
                ![Untitled](인공지능(1)/Untitled%2069.png)
                
        - 볼록 최적화
            - 목적 함수가 볼록 함수인 경우 사용 가능한 방법
        - 분기 한정법
            - 선형 계획 문제와 볼록 계획 문제를 조합
            - 모든 후보해를 체계적으로 늘어 놓아 최적화할 수치의 상한과 하한을 추정하고 불필요한 값들을 제거하는 고정 수행
            - 이산 최적화나 조합 최적화를 풀 때 사용
                
                ![Untitled](인공지능(1)/Untitled%2070.png)
                

# 회귀 분석

- 회귀 분석
    - 회귀 : 함수로 변화를 나타내고 피팅하는 것
    - 회귀 분석의 종류
        - 단순 회귀, 다항식 회귀, 로지스틱 회귀, 다중 회귀 등
    - 피팅에 사용하는 방법 : 최소 제곱법
    - 주어진 데이터로 어떤 함수를 만들어 낸 후 함수를 피팅하는 작업
    - 피팅 :함수에서 발생하는 차이(잔차의 크기)가 최소화되도록 함수를 조정하는 것
    - 잔차 : 회귀 직선을 통해 얻은 값(시뮬레이션값)과 실제값과의 차이
    - 일반선형 모델 : “잔차의 분포가 정규 분포를 따르는 것”을 전제로 만들어진 함수
    - 일반화 선형 모델 : 잔차의 분포가 임의의 분포로 만들어진 경우
    - 사용 예 : 선형화 문제 해결 시 이용
    - 어느 정도 신뢰할 수 있는가를 검정해서 통계 예측에 활용
    - 데이터의 잔차 정도를 통해 신뢰구간 표현하여 예측 결과의 정확성 표현
    - 단순 회귀
        - 요소들 사이의 비례 관계를 활용
        - 독립 변수가 한 개인 형태
        - 예 : 신장과 체중 사이의 관계, 임대주택 방 크기와 임대료 사이의 관계 등
        - 직선 y = ax + b에서 기울기 a와 절편 b를 알면 임의의 x에 대해서 y를 산출
            - y : 종속 변수, 목적 변수
            - x : 독립 변수, 설명 변수
    - 회귀 직선의 기울기와 절편 구하기
        - y = ax + b + e에서 a, b 구하기
        - 단순 회귀 모델 식을 기반으로 한 잔차 제곱 E (목적 함수)를 구함 (식 1)
            
            ![Untitled](인공지능(1)/Untitled%2071.png)
            
        - 기본 식에서 a와 b를 편미분으로 연립 방적식 설립 후 잔차 제곱이 최소화 되는 값 산출
            - 편미분은 a와 b가 독립 변수이므로 미분의 번거로움을 피하기 위해 사용
                
                ![Untitled](인공지능(1)/Untitled%2072.png)
                
        - 연립 편미분 방정식을 풀면 a와 b 각각을 구하는 식으로 변경 가능
            
            ![Untitled](인공지능(1)/Untitled%2073.png)
            
- 다중 회귀
    - 독립 변수가 증가할 경우 독립 변수 각각을 단순 회귀와 같은 방식으로 분석
        
        ![Untitled](인공지능(1)/Untitled%2074.png)
        
    - 다중 회귀 분석 : 독립 변수가 여러 개인 경우의 회귀 분석
    - 독립 변수가 여러 개가 되면 2차원 평면 상에 그래프로 표현할 수 없음
    - 2차원 평면 상으로 매핑을 위해 주성분 분석(PCA : Principal Component Analysis)을 이용
    - 독립 변수가 데이터 개수 보다 많은 경우에는 주성분 분석의 차원 감소를 위한 주성분 회귀와 부분 최소 제곱 회귀를 활용
    - 독립 변수가 늘 때의 단점
        - 회귀 분석의 결과를 신뢰할 수 없는 경우 발생
        - 답을 구할 수 없는 경우 발생
    - 다중 공선성(Multicollinearity)
        - 독립 변수란 각각이 선형 독립이어야 한다는 전제
        - 독립 변수가 증가하면 독립 변수들 사이에 상관 관계가 존재할 가능성이 높아짐
    - 다중 공선성 해결법
        - 부분최소제곱회귀와 L1 정규화 (LASSO)
        - 독립 변수들 중 상관 관계가 높은 변수를 제거
        - 변수를 변형하거나 새로운 관측치 사용
        - 상관 관계의 이유를 파악하여 해결
    - 다항식 회귀
        - 분석하고자 하는 설명 변수와 종속 변수가 선형적인 관계가 아닐 경우 선형 회귀 모델을 사용하면 큰 오차가 발생
            
            ![Untitled](인공지능(1)/Untitled%2075.png)
            
        - 산포도의 점 분포가 곡선 상에 위치할 경우 차수를 올려 대응하는 회귀 분석
            
            ![Untitled](인공지능(1)/Untitled%2076.png)
            
    - 과적합의 문제점
        - 차수가 계속 증가 시 모든 경우의 분포를 적합한 곡선으로 표현 가능한가?
        - 훈련 중인 데이터를 사용할 경우 잔차가 0에 근접
        - 예측 데이터를 사용할 경우 오차가 크게 발생할 확률이 높음
            
            ![Untitled](인공지능(1)/Untitled%2077.png)
            
        - 그림은 과적합의 예로 훈련 데이터로는 오차가 적을 수 있으나 어느 순간 실제 데이터를 사용하는 순간 오차가 다시 증가
        - 실제 회귀 분석 시 독립 변수의 차수를 낮게 설정하여 과적합 문제를 피하는 것이 중요
        - 신경망과 서포트 벡터 머신 등을 활용하여 과적합을 해결
    - 최소 제곱
        - 회귀 분석에서 함수에 피팅할 때에는 잔차가 최소가 되도록 함수를 조정
        - 최소제곱법은 잔차를 최소화 하는 일반적 사용법
        - 단순 회귀에서 언급한 연립 편미분 방정식을 만들어 답을 구할 수 있음
        - 독립 변수가 늘고 비선형 함수 모델 사용 시 대응관계가 복잡함
            
            ![Untitled](인공지능(1)/Untitled%2078.png)
            
        - 행렬을 이용하여 최소제곱법 계산
            
            ![Untitled](인공지능(1)/Untitled%2079.png)
            
        - 잔차 제곱의 합도 행렬로 표시하여 구할 수 있음
            
            ![Untitled](인공지능(1)/Untitled%2080.png)
            
        - 단순 회귀와 같이 E에 관해 w 각각의 성분을 편미분하여 이 값이 0이 되도록 하는 방정식을 행렬로 표현
            
            ![Untitled](인공지능(1)/Untitled%2081.png)
            
    - 정규방정식
        - 행렬 기반의 방정식으로 선형회귀상에서 알지 못하는 값을 예측하는 방법
            
            ![Untitled](인공지능(1)/Untitled%2082.png)
            
        - 역행렬을 구할 수 없을 때에는
            - QR 분해 알고리즘
            - 특이값 분해
    - QR 분해
        
        ![Untitled](인공지능(1)/Untitled%2083.png)
        
    - R언어에서의 QR 분해 함수
        
        ![Untitled](인공지능(1)/Untitled%2084.png)
        
    - 파이썬에서의 QR 분해 함수
        
        ![Untitled](인공지능(1)/Untitled%2085.png)
        
- 로지스틱 회귀
    - 종속 변수에 약간의 수정을 가한 선형 회귀
    - 다항식 회귀처럼 일반화 선형 모델의 하나로 분류
    - 종속 변수가 범주형 데이터를 대상으로 하여 입력 데이터가 주어졌을 때 해당 데이터의 결과가 특정 분류로 나뉨 → 분류 기법으로 사용
        
        ![Untitled](인공지능(1)/Untitled%2086.png)
        
    - 로짓(Logit) 변환
        - 일반식의 종속 변수 y에 로그를 적용하여 y’로 변환하는 것
            
            ![Untitled](인공지능(1)/Untitled%2087.png)
            
    - 로짓 함수를 이용한 함수 피팅
        
        ![Untitled](인공지능(1)/Untitled%2088.png)
        
    - 응용
        - 의학 또는 소셜 분석을 포함한 다양한 분야에 사용
        - 예) 부상을 입은 환자들의 사망 예측(Trauma and Injury Severity Score (TRISS))
        - 환자의 특정 병 감염 여부를 예측

# 가중 회귀분석

- 가중 회귀분석
    - 단순한 최소 회귀법은 특이값에 취약
    - 취약함을 보완하기 위해 가중치를 변화시켜 유연성을 톺임
        - LOWESS(Locally Weighted Scatterplot Smoothing)
            - 이변량 자료를 작은 윈도우로 나누어 각각의 구간에서 가중선형회귀(Weighted Linear Regression)를 하여 곡선을 구함
        - L2 정규화
        - L1 정규화
- 최소 제곱법 수정
    - 실제 답과 결과 값의 오차의 제곱의 합이 최소가 되는 해를 구하는 방법
        
        ![Untitled](인공지능(1)/Untitled%2089.png)
        
        ![Untitled](인공지능(1)/Untitled%2090.png)
        
    - 특이값에 취약
        - 데이터에 특이값이 포함되면 회귀 식의 예측 결과가 왜곡되는 현상이 발생
        - 왜곡 현상으로 인해 앞으로 수집할 데이터 예측 시 정확성을 잃음
        - 특이값에 패널티 부여나 제외를 통한 회귀 식을 수정
        - 데이터의 개수가 많은 경우 계산량이 매우 많이 증가함
    - 오차 제곱의 합을 Cost Function이라 함
- LOWESS 분석
    - 어떤 한 지점에 가중회귀 함수를 사용해 평활화를 실행한 회귀 식 도출 방법
    - 유연한 비선형 함수들을 적합하는 다른 기법
    - 목표점 x0에서 그 주변의 훈련 관측치들만을 사용하여 적합을 계산
    - 전체적으로 모든 데이터는 적합하지 않음
    - 최근 데이터가 중요할 경우 사용하며 최근 데이터에 중요도를 높여서 적합함
    - 목표점에서 먼 데이터들을 제외시켜 계산 상의 부담을 줄임
    - 목표점 근처의 데이터를 어떻게 수집하는 지가 관건
        - 평활화(Smoothing)
            - 연속성 있는 데이터와 관련 없는 데이터를 제거하거나 변화해서 데이터 전체를 연속성 있게 유지하는 작업
    - 임의로 설정한 폭 d(x)에서 xi 최소값부터 차례로 값을 증가시켜 x에 가장 가까운 xi값이 되도록 가중치 wi를 산출
        
        ![Untitled](인공지능(1)/Untitled%2091.png)
        
    - 평활화 실행을 위해 특이값을 없앨 수 있도록 가중치 w를 설정하는 방법으로 로버스트 평활화 사용
    - 중위 절대편차를 산출했을 때 6배 이상의 잔차 ri가 존재하면 wi를 0으로 설정
        
        ![Untitled](인공지능(1)/Untitled%2092.png)
        
    - 앞서 구한 가중치 계수 w와 독립 변수 x의 내적을 구했을 때 알 수 있는 종속 변수 y를 보정
    - 독립 변수의 값에서 멀어져 있는 점의 기울기를 조정하여 특이점으로 인한 영향을 무시하도록 보정
    - 단순 회귀를 반복해 실행하지만 실제 직선이 나타나지는 않음
        
        ![Untitled](인공지능(1)/Untitled%2093.png)
        
- L2 정규화, L1 정규화
    - 최소제곱법으로 구성한 방정식에 페널티를 부여
    - L2 정규화, L1 정규화, 일래스틱(Elastic) 넷
    - 벌칙 항(Penalty Term), 정규화 항(Regularization Term) : 패널티를 부여하는 항
        
        ![Untitled](인공지능(1)/Untitled%2094.png)
        
    - L2 정규화
        - 최소제곱법의 종속 변수인 잔차 제곱의 합에 가중치 계수인 wi ㅈ곱의 합을 패널티로 추가
        - 능형회귀
        - 패털티 항을 L2 노름(Norm)이라 함
            - 노름 : 벡터 공간의 원소들에 일종의 길이나 크기를 부여하는 함수
        - 𝜆 값은 다양한 값을 적용하면서 교차검증법으로 최적값 검색
        - 값이 크면 페널티도 강함
        - L2 정규화 실행 시 정규방정식에서 𝑋𝑇𝑋 항에 𝜆I(I는 단위 행렬) 추가
    - L1 정규화
        - Lasso (Least Absolute Shrinkage Selection Operator)
        - wi의 절대값을 패널티로 더해 줌
        - 패널티 항을 L1 Norm이라 함
        - L1 정규화를 실행하면 일부 w는 0이 되어 밀도가 낮아질 수 있음
        - 모델을 구축할 때 특징량 선택에 이용할 수 있음을 의미
        - 신호 처리와 패턴 인식에 사용하기 쉽고 다중 공선성 문제에도 대응 가능
        - L2 정규화는 일반적인 회귀 모델로 계산
        - L1 정규화는 볼록 최적화의 추정 알고리즘 사용
        - 데이터 생성에 사용한 함수 : 𝑦=0.001(𝑥³+𝑥²+𝑥)
        - 함수 y에 N(0, 0.1)을 따르는 무작위 값을 더해준 데이터 20개 이용
        - L2 정규화 사용 시 약간의 학습 효과가 있으며, L1 정규화는 최적의 모델링을 얻었으며 일라스틱 넷은 L1과 L2 정규식의 중간 정도 모델링 결과를 보임
    
    ![Untitled](인공지능(1)/Untitled%2095.png)
    

# 유사도

- 유사도
    - 회귀 분석 시 상관관계(상관계수)를 확인한다는 것은 유사도를 확인하는 것과 같음
    - 유사도 확인 방법
        - 코사인 유사도
        - 상호 상관함수
        - 자기 상관함수
        - 자카드 계수
        - 편집 거리
    - 추천 시스템이나 군집화 등 다양한 영역에서 유사도 사용
    - 다양한 측정법이 존재하는 만큼 시스템 특성에 맞는 적절한 방법 사용 시 좀 더 나은 결과를 얻을 수 있음
    - 변수값 쌍이 얼마나 비슷한가를 측정
    - 컴퓨터에서 자동으로 답을 추측하는 과정에서 매우 중요
    - 수학적인 유사도 개념
        - 코사인 유사도
            - 내적 공간의 두 벡터간 각도의 코사인값을 이용하여 측정된 벡터 간의 유사한 정도를 의미
        - 상관계수
            - 상관 관계의 정도를 파악
        - 상관 함수
            - 상관 관계의 정도를 파악하는 수식
        - 편집 거리(Edit Distance)
            - 단어의 유사도를 측정하는 방법 중 하나
        - 자카드 계수
            - 두 집합 사이의 유사도 측정 방법으로 두 집합이 동일하면 1, 공통 원소가 하나도 없으면 0
- 코사인 유사도
    - 변수값 x, y가 주어졌을 때  cos𝜃의 값이 유사도로 표시
    - 유사도는 0에서 1 사이의 값
    - 유사도가 높을 수록 1에 가까운 값
    - 변수 x와 변수 y가 같은 방향성을 갖는 것으로 유사도 측정
    - 벡터 길이와는 상관 없음
    - 어떤 개수의 차원에도 적용이 가능
    - 다차원의 양수 공간에서의 유사도 측정에 자주 이용
    - 예
        - 정보 검색 및 텍스트 마이닝 분야
            - 단어 하나 하나는 각각의 차원을 구성하고 문서는 각 단어가 문서에 나타나는 회수로 표현되는 벡터값
            - 이러한 다차원 공간에서 코사인 유사도는 두 문서의 유사도를 측정하는 매우 유용한 방법
        - 데이터 마이닝 분야의 클러스터 간의 응집도 측정
    
    ![Untitled](인공지능(1)/Untitled%2096.png)
    
    ![Untitled](인공지능(1)/Untitled%2097.png)
    
    - 문서 간의 유사도 계산 시 사용
    - 문서에 나타나는 단어의 출현 빈도를 구해 유사도 계산 식에 적용
    - 변수 값 쌍은 산포도를 사용해 점의 집합으로 표현
        
        ![Untitled](인공지능(1)/Untitled%2098.png)
        
        ![Untitled](인공지능(1)/Untitled%2099.png)
        
    - 코사인 유사도 예
        - 신문 기사 별 유사도 분석
        - 코사인 유사도 식을 이용하여 단어의 빈도 표의 값을 적용, 유사도 산출
            
            ![Untitled](인공지능(1)/Untitled%20100.png)
            
    - 상관 관계
        - 2개의 확률 변수 사이의 분포 규칙의 관계
        - 분포 규칙
            - 한쪽이 증가하면 다른 한쪽도 증가하고 한쪽이 감소하면 다른 한쪽도 감소하는 것
        - 대부분 선형 관계의 정도를 의미
    - 상관 계수
        - 보통 피어슨 상관 계수를 의미
    - 피어슨 상관 계수
        
        ![Untitled](인공지능(1)/Untitled%20101.png)
        
        - 두 변수 간의 관련성을 구하기 위해 보편적으로 사용
        - 1 : x와 y가 완전히 동일함
        - 0 : x와 y가 전혀 다름
        - -1 : x와 y가 반대방향으로 완전히 동일함
        - 1 또는 -1에 가까울 수록 강한 상관 관계
        - 보통 0.7 이상이면 상관 관계가 있다고 판단
        
        ![Untitled](인공지능(1)/Untitled%20102.png)
        
    
- 상관계수
    - 상관계수의 의미
        - 상관계수의 절대값이 1에 가까움
            - 단순 회귀의 점 분포에 불규칙성이 작음을 의미
        - 점 분포에 불규칙성이 작아도 상관계수는 0에 가까울 수 있음
        - 불규칙성이 전혀 없어 표준 편차가 0일 경우 상관 계수를 산출 할 수 없음
            
            ![Untitled](인공지능(1)/Untitled%20103.png)
            
    - 상관계수 특징
        - 상관계수는 단위가 없음, 측정 단위와 독립적
        - 상관계수는 방향성을 갖지 않음
        - 상관계수의 값이 0.8일 경우 상관 계수가 0.4인 경우보다 2배의 상관 관계를 갖는 것은 아님
    - 상관 관계를 사용하지 못하는 경우
        - 경향을 따르지 않는 이탈 값들이 존재할 경우
        - 두 변수 간의 관계가 비선형일 경우
            
            ![Untitled](인공지능(1)/Untitled%20104.png)
            
    - 스피어만의 순위 상관 계수
        - 피어슨 상관 계수의 특별한 경우
        - 데이터가 서열 척도인 경우 자료의 값 대신 순위를 이용하는 경우의 상관 계수
        - 자료에 이상점이 있거나 표본 크기가 작을 경우 유용
        - 피어슨 상관 계수 식을 이용하여 확률 변수들의 값을 순위로 계산
            
            ![Untitled](인공지능(1)/Untitled%20105.png)
            
    - 스피어만의 순위 상관 계수 예
        - 수학을 잘하는 학생이 영어도 잘하는 것과의 상관 관계를 알아보고자 할 경우
        - 학생 10명의 표본을 이용하여 수학 순위와 영어 순위를 작성
        - 학생 별로 수학을 잘하는 학생이 영어도 잘하는지 스피어만의 순위 상관 계수 활용
        - 결과가 0.703으로 상관 관계가 있는 것으로 분석됨
            
            ![Untitled](인공지능(1)/Untitled%20106.png)
            
- 거리와 유사도
    - 유사도를 거리와 같은 개념으로 이해
    - 거리가 가까울 수록 유사도가 높은 것으로 분석
    - 종류
        - 편집 거리(Edit Distance)
        - 레벤슈타인 거리(Levenshtein Distance)
        - 해밍 거리(Hamming Distance)
        - 유클리드 거리(Euclidian Distance)
        - 마할라노비스 거리(Mahalanobis Distance)
    - 편집 거리(Edit Distance)
        - 치환, 삽입, 삭제의 세 요소를 각각 페널티를 설정하는 형태를 취해 페널티의 합계를 점수로 설정하여 유사도 규정
        - 예: spring과 print의 유사도 계산
            
            ![Untitled](인공지능(1)/Untitled%20107.png)
            
    - 자카드 계수
        - 집합 2개의 유사도를 구할 때
        - 집합 2개의 공통 요소 수를 전체 요소 수로 나눈 것으로 표현
        - 벤다이어그램을 이용하여 간편하게 적용 가능
        - 집합 구성 요소가 수치인지 문자열인지 고려 없이 적용 가능
            
            ![Untitled](인공지능(1)/Untitled%20108.png)
            
            ![Untitled](인공지능(1)/Untitled%20109.png)
            
            ![Untitled](인공지능(1)/Untitled%20110.png)
            

# 그래프 이론

- 그래프
    - 점과 선을 연결한 것
    - 점을 꼭지점, 정점(Vertex), 노드(Node)
    - 선을 변, 간선(Edge)
    - 연결 그래프
        - 모든 정점 사이를 연결한 그래프
        - 모든 정점의 경로가 존재하는 그래프
            - 고립 정점 : 어떤 정점도 연결되지 않은 정점
                
                ![Untitled](인공지능(1)/Untitled%20111.png)
                
    - 동형 그래프
        - 연결되어 있는 정점들은 어느 위치에 있는지 관계가 없음
        - 정점을 이동해도 같은 그래프가 될 수 있음
            
            ![Untitled](인공지능(1)/Untitled%20112.png)
            
    - 복잡한 그래프
        - 평행 변 (Parallel Edge)
            - 그래프에서 정점 2개가 2개 이상의 변으로 연결되는 변
        - 양끝이 같은 변(Self-loop)
            - 1개의 정점에 시작과 끝이 연결된 변
                
                ![Untitled](인공지능(1)/Untitled%20113.png)
                
- 무향 그래프와 유향 그래프
    - 유향 그래프(Directed Graph)
        - 그래프의 변에 방향이 존재하는 그래프
        - 유향 비순회 그래프(Direct Acyclic Graph; DAG)
            - 임의의 정점에서 출발한 후 해당 정점에 돌아오는 경로가 하나인 그래프
        - 가중 그래프(Weighted Graph)
            - 유향 그래프 중 가중치 정보가 추가된 그래프
            - 간선 가중 그래프
                - 변에 가중치를 나타낸 그래프
            - 정점 가중 그래프
                - 정점에 가중치를 나타낸 그래프
            - 네트워크라고도 함
                - 신경망, 베이즈 네트워크 등
                - 상태 전이 다이어그램도 네트워크의 한 종류
    - 무향 그래프(Undirected Graph)
        - 변에 방향이 존재하지 않는 그래프
            
            ![Untitled](인공지능(1)/Untitled%20114.png)
            
- 그래프의 행렬 표현
    - 인접 행렬(Adjacency matrix)
        - 정점 사이의 관계를 나타내는 행렬
        - 정점 수가 n일 때 n x n 행렬로 표현
        - 정점이 연결되어 있으면 1, 연결되어 있지 않으면 0으로 표현
    - 근접 행렬(Incidence matrix)
        - 정점과 변의 관계를 나타내는 행렬
        - 정점 수가 n, 변의 수가 m일 때 n x m 행렬로 표현
        - 정점과 변이 연결되어 있으면 1, 연결되어 있지 않으면 0으로 표현
    - 변에 가중치가 있는 그래프일 경우 인접 행렬 요소를 0과 1이 아닌 가중치 값으로 구성
    - 그래프를 행렬로 표현하면 그래프를 표 형식으로 변경이 쉬움
    - 표 형식의 값을 가중 그래프로 변환해서 히트 맵처럼 표현 가능
    - 네트워크 분석 : 가중 그래프를 이용한 데이터 분석 방법
        
        ![Untitled](인공지능(1)/Untitled%20115.png)
        
- 트리 구조 그래프
    - 그래프에 있는 여러 개의 정점에서 출발점이 되는 정점으로 돌아가는 경로가 유일한 경우
    - 출발점이 되는 정점이 막다른 정점인 그래프
    - 루트(Root) : 트리 구조 그래프의 출발점이 되는 정점
    - 의사 결정 트리 : 통계 모델 예측을 위한 조건 분기에 사용되는 규칙으로 트리 구조 사용
    - 탐색 트리 : 상태를 나누는 수단으로 트리 구조 사용
        
        ![Untitled](인공지능(1)/Untitled%20116.png)
        

# 그래프 탐색

- 그래프 탐색
    - 트리 구조와 이진 탐색 트리
    - 너비 우선 탐색
    - 깊이 우선 탐색
    - 에이스타(A*) 알고리즘
    - 동적 계획법
- 탐색 트리 구축
    - 트리 구조 그래프를 출발점이 되는 정점(루트, 초기 상태)에서 다른 정점을 향해 나아가는 모습을 통해 여러 가지를 선택할 수 있는 상태 표현
    - 출발점에서 종착점으로 가는 경로를 탐색하는 경우 유용
    - 출발점에서 목적지를 노드로 구성한 후 분기를 이용해 상태 선택
    - 예
        - 제로섬 유한 확정 완전 정보 게임 : 체스, 오셀로 등
        - 경로 탐색 : 미로 찾기, 대중교통 환승 등
    - 2인 플레이 게임 시 어느 플레이어를 선택하느냐에 따라 대전하는 상대가 달라짐
        
        ![Untitled](인공지능(1)/Untitled%20117.png)
        
    - 미로에서 출발점으로부터 어느 경로를 선택하느냐에 따라 최종 목적지에 도달 경로를 결정
        
        ![Untitled](인공지능(1)/Untitled%20118.png)
        
    - 탐색 트리는 노드에 이익과 비용 같은 평가 값을 저장해 두고 목적지에 도달하는 최적 경로를 검색
    - 평가 값 : 최적 경로 선택 시 필요한 ‘상태’
    - 예(대중교통 환승)
        - 평가 값 : 최소 이동 시간, 최소 환승 횟수, 필수 경유지, 환승 요금 등
        - 비용을 평가 값으로 환산하여 최적 경로 탐색 시 활용
    - 다단계 (의사) 결정 문제
        - 최적 경로 탐색 시 현재 시간 t에 해당하는 상태에 어떤 행동을 했을 때 얻을 수 있는 이익이나 지불 비용을 계산하여 다음 시각 t + 1의 상태를 결정하는 것
        - 위 과정을 반복 실행하여 목적지에 도달했을 때 시간 T의 이익을 최대화 또는 비용을 최소화 하는 계획 문제 해결
            
            ![Untitled](인공지능(1)/Untitled%20119.png)
            
    - 데이터베이스 시스템에 활용
        - 이진 탐색
            - 정렬된 데이터를 반으로 나눠 저장하는 작업 반복 수행
            - 트리 구조를 만든 후 원하는 데이터를 빠르고 효율적으로 검색
            - 이러한 트리를 이진 탐색 트리라고 함
        - 실제 데이터베이스 시스템은 이진 탐색 트리보다 유연한 B 트리 등을 사용
        - 온톨로지 트리 : 데이터 간의 관계를 나타내는 요소를 추가
        - 시멘틱 네트워크 : 네트워크 기반의 지식 표현 방법
    - 이진 탐색 트리
        - 이진 탐색과 연결 리스트를 결합한 자료구조의 일종
        - 이진 탐색의 효율적인 탐색 능력은 유지
        - 빈번한 자료 입력과 삭제를 가능하게 고안됨
        - 이진 탐색 트리 특징
            - 완전 이진 트리
            - 각 노드의 왼쪽 서브 트리에는 해당 노드보다 작은 값들로 구성된 노드
            - 각 노드의 오른쪽 서브 트리에는 해당 노드보다 큰 값들로 구성된 노드
            - 중복된 노드가 허용되지 않음
            - 왼쪽/오른쪽 서브 트리 또한 이진 탐색 트리
        - 중위 순회 방식을 사용
        - 이진 탐색 트리 예
            - 탐색
                
                ![Untitled](인공지능(1)/Untitled%20120.png)
                
                - 10을 탐색한다고 가정
                - 10은 7보다 크므로 오른쪽 노드로 이동
                - 10은 8보다 크므로 오른쪽 노드로 이동
                - 10을 탐색
            - 삽입
                
                ![Untitled](인공지능(1)/Untitled%20121.png)
                
                - 4를 삽입한다고 가정 (그림은 삽입 후 결과)
                - 4는 7보다 작으므로 왼쪽 노드로 이동
                - 4는 3보다 크므로 오른쪽 노드로 이동
                - 4는 5보다 작으므로 왼쪽 노드로 이동하여 삽입
            - 삭제
                
                ![Untitled](인공지능(1)/Untitled%20122.png)
                
                - 탐색과 마찬 가지로 과정으로 삭제할 노드를 검색하여 삭제
                - 말단 노드인 경우는 쉽게 삭제 가능
                - 하나의 자식 노드를 갖는 경우는 노드 삭제 후 자식 노드를 부모 노드에 연결
                - 두 개의 자식 노드를 갖는 경우는 두 자식 노드 중 어느 노드를 부모 노드와 연결할 것인지에 따라 다른 모양이 나타날 수 있음
                - 그림에서 30을 삭제할 경우 노드 25를 노드 20에 연결할 것인지 노드 42를 노드 20에 연결할 것인지에 따라 모양이 다르게 나타남
    - B 트리
        - 데이터베이스와 파일 시스템에서 널리 사용되는 트리 자료구조의 일종
        - 이진 트리를 확장해 노드가 가질 수 있는 자식 노드의 최대 숫자가 2보다 큰 트리 구조
        - 방대한 양의 저장된 자료 검색 시 검색어와 자료의 일대 일 비교는 비효율적
        - 자료를 정렬된 상태로 보관
            
            ![Untitled](인공지능(1)/Untitled%20123.png)
            
    - 온톨로지 트리
        - 의미 네트워크에 메타 데이터를 추가한 데이터 작성법
        - 지식 표현과 활용을 위한 인공지능 분야에 처음 적용
        - 에이전트의 상호작용을 통해 의미 있는 문제 해결을 위해 지식 기반 필요성이 대두하여 개념 계층도 이용
    - 시멘틱 네트워크
        
        ![Untitled](인공지능(1)/Untitled%20124.png)
        
        - 네트워크 기반의 지식 표현 방법
        - 객체, 개념, 사건들을 표현하는 노드의 집합과 노드 사이의 관계를 표현하며 연결하는 아크의 집합으로 구성
        - 장점
            - 복잡한 분류나 인과관계를 갖는 추론에 자연스러운 표현이 가능
        - 단점
            - 너무 복잡하여 다루기 힘들 수 있음
- 탐색 트리 추적 방법
    - 막힌 지점이 있는 미로나 탐색 트리의 경로 탐색 시 최소 단계(회수)에 목적지에 도달하는 것이 목표인 경우
    - 탐색 순서에 따른 구분
        - 깊이 우선 탐색(Depth First Search, DFS)
        - 너비 우선 탐색(Breath First Search, BFS)
        - 도달하는 목표 지점까지의 경로를 미리 파악할 수 있으면 어느 방법이 더 효율적인지 명확하지만 그런 경우는 없으므로 두 방법 모두 장단점을 가질 수 있음
        - 목적지는 해당 노드의 상태 평가 값과 이를 계산하는 평가 함수로 결정
        - 상태 평가 값의 예
            - 승부의 포석, 막다른 노드나 목적지, 점수 등
    - 깊이 우선 탐색(Depth First Search, DFS)
        
        ![Untitled](인공지능(1)/Untitled%20125.png)
        
        - 루트 노드에 연결된 경로 중 하나를 선택해 막다른 노드에 도착할 때까지 일단 탐색
        - 다시 바로 앞 노드로 이동하여 다음 막다른 노드에 도착할 때까지 탐색 반복
    - 너비 우선 탐색(Breath First Search, BFS)
        
        ![Untitled](인공지능(1)/Untitled%20126.png)
        
        - 루트 노드와 연결된 노드를 모두 탐색 후 바로 다음 깊이의 노드들을 전부 탐색하는 과정을 반복
    - 탐색 트리의 탐색에 필요한 목록
        - 오픈 리스트(Open List)
            - 탐색 대상 노드와 연결된 주변 노드를 포함하는 탐색 노드의 목록
        - 클로즈드 리스트(Closed List)
            - 탐색을 종료한 노드의 목록
        - LIFO(깊이 우선 탐색 시)
            - 탐색할 노드를 오픈 리스트의 맨 위에 추가해 첫 번째 노드부터 차례대로 탐색
            - 마지막으로 목록에 넣은 노드의 탐색 결과가 먼저 나옴
            - 스택(Stack) 구조 사용
        - FIFO(너비 우선 탐색 시)
            - 탐색할 노드를 오픈 리스트의 마지막에 추가
            - 먼저 목록에 넣은 노드의 탐색 결과가 먼저 나옴
            - 큐(Queue) 구조 사용

# 탐색 방법

- 효율적인 탐색 방법
    - 깊이 우선 탐색 및 너비 우선 탐색은 탐색할 노드 순서를 결정하는 것
    - 효율적인 탐색 방법을 고려하여 처리 시간 단축 필요
    - 비용에 따른 탐색 방법
        - 사전 지식이나 경험(휴리스틱)을 이용하여 처리 시간 단축
        - 비용의 종류
            - 초기 상태 : 상태 s의 최적 경로 이동에 드는 비용의 총합 g(s)
            - 상태 s : 목표하는 최적 경로 이동에 드는 비용의 총합 h(s)
            - 상태 s를 거치는 초기 상태 : 목표의 최적 경로 이동에 드는 비용의 총합 f(s) = g(s) + h(s)
        
        ![Untitled](인공지능(1)/Untitled%20127.png)
        
        - 스택이나 큐에 포함되는 노드의 순서를 변경하는 원리
        - 최적 탐색은 탐색량이 많아지는 단점을 포함
        - 최선 우선 탐색은 잘못된 결과가 나올 수 있는 단점 포함
    - 에이스타(A*) 알고리즘
        
        ![Untitled](인공지능(1)/Untitled%20128.png)
        
        ![Untitled](인공지능(1)/Untitled%20129.png)
        
    - 게임 트리를 전략에 이용하는 방법
        - 게임 트리 : 턴마다 자신과 상대를 통해 노드를 구성
        - 게임 트리의 끝 지점 : 해당 시점의 상태(자신의 유리, 불리를 나타내는 점수) 보유
        - 자신의 턴에서는 자신이 유리하다고 가정하고 상대 턴에서는 자신이 불리하다고 가정하고 전략을 세움
        - 탐색 노드를 줄여 시간을 줄임
            - 미니맥스(Mini-max)의 원리
            - 알파베타 가지치기(Alpha-beta Pruning)
    - 미니 맥스 원리(최소극대화 원리)
        - 자신의 턴에 점수를 최대화하고, 상대의 턴에 점수를 최소화 하도록 노드 선택
        - 다음 선택 변을 줄여 탐색 시간을 줄이는 최적 탐색 실행 고려
        - 두 명의 참가자가 존재하는 제로섬 게임 이론으로부터 형성
        - 복잡한 게임 및 불확실성이 존재할 때의 일반적 의사 결정에까지 적용 확정
    - 알파베타 가지치기
        - 노드를 왼쪽부터 탐색해 변을 잘라 내는 작업 수행
        
        ![Untitled](인공지능(1)/Untitled%20130.png)
        
        ![Untitled](인공지능(1)/Untitled%20131.png)
        
    - 바둑이나 장기 등 탐색 공간, 즉 탐색할 노드 수가 방대한 경우 메모리 용량과 탐색 시간이 부족
    - 효율적인 탐색 대상 선택
        - 몬테카를로 트리 탐색(Monte Carlo Tree Search, MCTS)
            - 의사 결정을 위한 체험적 탐색 알고리즘
            - 게임에 주로 적용
        - 이진 의사 결정 다이어그램(Binary Decision Diagram, BDD)
            - 불리안 함수를 표현하기 위해 사용되는 자료구조
            - 관계 집합의 압축 표현
                
                ![Untitled](인공지능(1)/Untitled%20132.png)
                
        - ZDD(Zero-suppressed Decision Diagram)
            - 이진 의사 결정 다이어그램의 한 종류
            - 불리안 함수의 함축적 표현
                
                ![Untitled](인공지능(1)/Untitled%20133.png)
                
- 동적 계획법
    - 경로 탐색에서 체크포인트(경유지)를 통과할 필요가 있거나 탐색 필요
    - 비용이 있을 때 노드에서 노드를 이동하는 모습을 ‘시계열 기준 상태 변화’로 가정
    - 어떤 상태에서 다음 상태로 전환하는 것은 비용을 고려하면서 결정을 수 차례 반복하는 다단계 결정 문제로 취급
    - 다단계 결정 문제로 다뤄서 얻는 경로의 평가 함수 J의 계산 결과를 극대화 하여 경로 탐색 목표를 결정
    
    ![Untitled](인공지능(1)/Untitled%20134.png)
    
    ![Untitled](인공지능(1)/Untitled%20135.png)
    
    ![Untitled](인공지능(1)/Untitled%20136.png)
    
    ![Untitled](인공지능(1)/Untitled%20137.png)
    
    ![Untitled](인공지능(1)/Untitled%20138.png)
    

# 신경망의 개요

- 신경망이란?
    - 신경망은 인간 두뇌의 생물학적 뉴런의 작용을 모방한 모델
    - 신경망은 인간 두뇌의 병렬성(parallelism)을 모델링
    - 뉴런들로부터의 입력을 일정한 함수를 거쳐 출력
    - ‘인공신경망’(Artificial Neural Networks)으로 부르기도 함
    - 문자인식, 음성인식, 영상인식, 자연어 처리 등에 이용
- 신경망의 발상
    - 인공지능을 기호주의와 연결주의로 나누었을 때 신경망은 연결주의의 대표적인 모델
    - 인간 두뇌에 있는 뉴런의 연결을 모방
    - 인간의 지능이 뉴런들 사이의 연결로부터 시작된다는 발상
    - 두뇌가 어떤 원리에 따라 작동하는지가 주된 관심
    - 병렬처리 구현에 중점을 둠
    - 학습과 관련된 지능적인 역할을 훌룡하게 수행
- 신경망의 학습 기능
    - 모든 신경망의 공통적인 주요 역할은 ‘학습(learning)’ 기능
    - 문자, 숫자, 음성, 영상, 동영상 등의 학습과 인식 능력이 필요한 인공지능
    - 음성이나 영상 정보 등은 대규모 멀티미디어 정보
    - 데이터가 크고 다루기가 매우 어려운 것을 학습하고 인식
    - 선형 모델보다 해석이 어려운 비선형 모델을 구성
- 신경망의 시작과 발전 과정
    - 1943년 맥클럭-피츠 모델에서의 논리로 출발
    - ‘헵’의 연결강도(weight) 조정을 위한 학습 규칙 나옴
    - 헵의 법칙(Hebb’s Rule)과 형식 뉴런
        - 유전 알고리즘과 함께 생명 현상에서 영감을 얻은 기법
        - 신경 세포는 다른 신경 세포에게 전기 신호를 받았을 때 전기 신호가 일정 기준을 넘으면 다음 신경 세포로 신호를 전달
            - 이 과정을 수학적 모델(맥컬록-피츠 모델)로 고안한 것
    - 맥컬록-피츠 모델
        
        ![Untitled](인공지능(1)/Untitled%20139.png)
        
    - 1차 붐
        - 1950년대 퍼셉트론 개발로 신경망 붐을 주도
        - 단순한 XOR 문제의 한계에 도달
    - 2차 붐
        - 1980년대 다층 퍼셉트론 개발과 오차 역전파법으로 붐을 주도
        - 다층 퍼셉트론 학습 시 기울기 소실 문제로 한계에 도달
    - 3차 붐
        - 2000년대 활성 함수의 대체로 기울기 소실 문제를 해결
        - 이미지 인식 경연대회(ILSVRC)에서 알렉스넷으로 신경망; 딥러닝의 붐을 주도
- 기본 개념
    - 실제 신경 세포 간의 전달 물질 이동은 시냅스를 통해 이뤄짐
    - 받는 쪽 신경 세포의 세포막 안팎에 미세한 전위차(막 전위)를 발생시켜 전기 신호로 시각화
    - 형식 뉴런(formal neuron; 소자) : 신경 세포의 연결 모델
    - 입력을 통해 얻은 값을 합산한 후 필터를 거쳐 값을 출력
    - 뉴런에서 값을 출력할 때 일정 기준은 단위 계산 함수 H로 결정
        
        ![Untitled](인공지능(1)/Untitled%20140.png)
        
    - 헵의 법칙
        - 시냅스를 통한 신경 세포의 상호 작용이 증가하면 시냅스가 더 견고하게 강화
        - 상호 작용이 감소하면 시냅스는 약해져 신경 회로를 사용하지 않음
        - 시냅스의 유연한 연결, 즉 가소성 있는 변화를 의미
    - 학습과의 연관성 증명
        - 신경 세포의 연결이 더 견고하면 기억력 향상과 운동 능력 습득 같은 학습 작용에 도움을 줌
        - 수학적 개념 도입 시 형식 뉴런에 헵의 법칙 적용에 따르면 입력값과 출력값에 의해 가중치 변화
            
            ![Untitled](인공지능(1)/Untitled%20141.png)
            
    - 형식 뉴런을 여러 개 이어서 ‘수학적인 신경회로’를 구성한 것
    - 계층 : 같은 종류의 형식 뉴런을 여러 개 병렬로 배열해 유닛을 형성하는 것
        
        ![Untitled](인공지능(1)/Untitled%20142.png)
        
- 특징
    - 분산성/병렬성(Dispersion/Parallelism)
        - 같거나 비슷한 뉴런끼리 구성된 다수 개의 노드 존재
        - 서로 연결되어 정보 교환
    - 국소성(Locality)
        - 개별 뉴런이 받는 정보는 결합해 있는 다른 뉴런의 입력 신호 상태, 자신의 내부 상태, 출력 신호의 상태, 다음 연결부의 뉴런 상태가 됨
    - 가중합(Weighted Sum)
        - 입력 받을 때 결합 상황에 따른 가중치(결합 하중) 연산 실행
        - 가중치가 적용된 입력의 합산 또는 합산한 값을 비선형 함수로 변환한 값을 내부 상태로 설정
    - 가소성(Plasticity)
        - 결합 하중은 뉴런이 얻는 정보로 변화
        - 학습과 자기 조직화에 활용
    - 일반성(Generality)
        - 학습한 특정 상황에서 바람직한 행동을 하는 것은 물론이고 학습하지 않은 상황도 보간법과 외삽법 등으로 대응
- 활성화 함수
    - 형식 뉴런에서 받은 입력 값을 출력할 때 일정 기준에 따라 출력 값을 변화시키는 비선형 함수
    - 계단 함수
        - 단위 계단 함수와 비슷하며 둘 다 디랙 델타 함수(Dirac delta function) 과 관련된 (−∞ ~+∞) 적분을 계산한 결과
        - 디렉 델타 함수(Dirac delta function)
            
            ![Untitled](인공지능(1)/Untitled%20143.png)
            
    - 시그모이드 함수
        - x = -∞ 일 때, 0, x = +∞일 때 1에 무한히 접근
        - x = 0일 때 0.5가 되는 연속 함수
        - 로지스틱 회귀에서 이용했던 로지스틱 함수의 역함수와 같은 방식으로 계산
        - Sigmoid(x) 또는 𝜎(𝑥)와 같은 식으로 표기
        - 유사한 함수로 x= −∞ 일 때 0, x = +∞ 일 때 1에 무한히 접근하며 x = 0 일 때 0이 되는 tanh(x)(쌍곡선 탄젠트함수)도 사용
            
            ![Untitled](인공지능(1)/Untitled%20144.png)
            
    - 오차 함수(목적 함수)
        
        ![Untitled](인공지능(1)/Untitled%20145.png)
        
        ![Untitled](인공지능(1)/Untitled%20146.png)
        
        ![Untitled](인공지능(1)/Untitled%20147.png)
        

# 초기의 신경망

- 퍼셉트론
    - 맥컬록-피츠 모델을 기반으로 두는 학습 기계
    - 헵의 법칙을 적용하여 출력값에 따라 플러스와 마이너스로 진동하도록 가중치 업데이트
    - 가중치 업데이트
        
        ![Untitled](인공지능(1)/Untitled%20148.png)
        
    - 단순 퍼셉트론
        - 퍼셉트론 수렴 정리(perceptron convergence theorem) : 긍정적인 예와 부정적인 예에서 학습 데이터를 선형 분리. 가능하다면 반드시 유한 횟수를 반복 실행해 평면 분리 상태를 찾을 수 있다는 개념
    - 데이터 선형 분리가 불가능하면 퍼셉트론 학습 적용 불가
    - 선형 분리할 수 있더라도 평면 분리 상태로 만드는데 시간이 오래 소요될 한계 포함
        
        ![Untitled](인공지능(1)/Untitled%20149.png)
        
    - 선형 함수 불가능 예
        - Exclusive-Or(XOR) 함수는 선형 분리가 불가능
        - 하나의 직선이 아닌 곡선에 의해서만 분리가 가능
            
            ![Untitled](인공지능(1)/Untitled%20150.png)
            
    - 로젠블럿의 단층 퍼셉트론
        - 최초의 신경망 모델인 ‘퍼셉트론’은 단층으로 구성
        - 신경망 하드웨어 장치인 ‘마크 I 퍼셉트론’ 1975년에 제작
        - 마크 I(one) 퍼셉트론은 A, B, C 등의 문자를 인식
        - 20 x 20 개의 화소(pixel)를 가진 마크 I 퍼셉트론 화면
        - 마크 I 퍼셉트론에서 연결선으로 연결강도 조정
        - 학습을 위해 몇 km나 되는 연결선을 사용
    - 단층 퍼셉트론의 구조
        - 단 1개 층의 연결 강도 조정
        - 오차에 대한 피드백 학습
            
            ![Untitled](인공지능(1)/Untitled%20151.png)
            
    - 퍼셉트론의 학습 과정
        - 연결 강도를 조정하며 학습
            1. 연결강도들과 임계값을 초기화
            2. 새로운 입력과 기대되는 출력을 제시
            3. 실제 출력값을 계산
            4. 연결강도를 재조정
            5. 더 이상 조정이 없을 때까지 2 단계로 가서 반복 수행
    - 단층 퍼셉트론의 2가지 제한점
        - 단층 퍼셉트론의 출력은 0 또는 1(1 또는 -1) 만 가짐
        - 선형 분리가 가능한 집합만을 분리 가능
    - XOR 함수의 문제점
        - 선형 분리가 불가능
        - 한 직선으로 두 집합을 교차하지 않고 나눌 수 없음
        - 이 점은 단층 퍼셉트론 학습에서 매우 심각한 문제점
        - 1980년 중반, 다층 퍼셉트론은 XOR 문제부터 해결
    - 단층 퍼셉트론의 한계점과 기여
        - XOR 문제 해결 불가, 10여 년 동안 고나심이 멀어짐
        - 단층 퍼셉트론은 학습 모델로서는 적절하지 않음
        - 1980년대 중반 다층 퍼셉트론 모델의 기반이 됨
            - 문자 인식을 비롯한 여러 분야에 폭넓게 응용되었음
            - 신경망 연구의 새로운 장을 열게 된 결정적인 계기

# 다층 퍼셉트론

- 새로운 신경망 시대의 도래
    - 1969년 이후 신경망 연구가 10여 년간 침체
    - 1980년대 중반에 다층 퍼셉트론 모델이 제안됨
    - 단층 퍼셉트론 모델에 하나 이상의 은닉층을 추가로 사용
    - 단층 퍼셉트론의 XOR 문제를 해결하여 비선형 문제에 도입
- 다층 퍼셉트론
    - 입력 계층과 출력 계층만 있는 단순 퍼셉트론의 단점은 선형 분리 데이터에만 적용 가능하며 계산 시간이 오래 걸림
    - 단순 퍼셉트론을 여러 번 서로 연결하여 비선형으로 보이는 분포를 선형 분리할 수 있는 분포로 변환
    - 순방향으로 계층마다 출력을 계산한 후 오차 역전파법을 이용해 출력 계층에서 역방향으로 가중치 업데이트 실행
    - 네트워크 학습 전제와 정답 데이터 제공 시 동작
    - 정답 데이터와의 조율은 최소 제곱 오차 등을 반영한 오차 함수를 만든 후 경사 하강법 이용
        
        ![Untitled](인공지능(1)/Untitled%20152.png)
        
- 오차역전파 법
    - 중간 계층을 갖는 신경망은 출력 계층에서 학습 데이터와 값의 오차를 이용해 중간 계층 뉴런의 특성을 변화시킬 수 있음 → 오차 역전파 법(back propagation)
    - 다층 퍼셉트론의 학습 규칙으로 적용
    - 진행 흐름이 한 방향으로 되어 있는 신경망에서도 피드백 메커니즘 생성 가능
    - 과거 단층 퍼셉트론의 제한점 극복
    - 특히 XOR 함수의 선형 분리 문제 등 해결
    - 침체에 빠졌던 신경망 연구가 새롭게 활기를 띠게 됨
    - 역전파 알고리즘은 입력층에서 은닉층을 거쳐 출력층, 다시 반대 방향으로 되돌아오면서 학습
- 다층 퍼셉트론의 학습 과정과 규칙들
    - 델타규칙, 최급 하강법, 일반화 델타규칙 등이 사용됨
    - 델타규칙(delta rule)은 출력과 목표 출력값과의 오차 제곱의 총합을 최소로 하도록 연결 강도를 조정하는 규칙
    - 최급 하강법(gradient descent method)은 곡면에서 오차의 제곱이 가장 많이 감소하는 방향으로 기울기를 따라가며 변화하는 방법
- 역전파 학습 알고리즘과 지역최소점(local minima) 문제
    - 역전파 학습 알고리즘의 단점
    - 오랜 학습 시간, 낮은 확률이나 지역 최소점 봉착 가능
    - 특히 최급 하강법은 지역 최소점에 머물 가능성이 큼
    - 우리는 지역 최소점(Local Minima)이 아닌 전역적 최소점(Global Minima)을 추구
    - 그러나 신경망이나 인공지능에서는 다소 불가피함
        
        ![Untitled](인공지능(1)/Untitled%20153.png)
        
- 다층 퍼셉트론 모델의 기타 응용
    - 패리티 문제, 부호화 문제, 대칭성 문제 등
    - 텍스트를 음성으로 변환하는 네트워크 시스템 개발
    - 주식시장의 예측, 다른 언어들 간의 번역
    - 공장 자동화, 실시간 음성인식, 로봇 등

# 통계 모델과 확률 분포

- 통계 모델과 확률 분포
    - 머신 러닝
    - 일반화 선형 모델과 기저함수
    - 주요 기저 함수
    - 기타 비선형 함수
- 확률 기반
    - 일반적인 사건(Event)의 발생들은 확률로 표현 가능
        - 동전을 던질 때 앞면과 뒷면 어느 방향이 나올 것인가
        - 태풍이 올 때 날씨는 어떨까
    - 회귀 분석 시 설명 변수와 목적 변수들 간에 선형함수를 통한 피팅 방법 사용
    - 피팅을 위한 오차 함수 설정 시 확률이 관여됨
        - 두 변수 간의 측정 결과에 따른 측정 오차가 확률 분포를 따름
        - 측정오차는 정규 분포 등의 분포로 표현
    - 확률 분포 모델
        - 설명 변수와 목적 변수가 갖는 어떤 확률에 근거한 관계
        - 임의의 분포를 갖는 오차로 표현
            
            ![Untitled](인공지능(1)/Untitled%20154.png)
            
- 머신 러닝
    - 학습
        - 신경망에서 데이터 입력을 통해 스스로 네트워크의 가중치를 변화시키는 것
    - 머신 러닝
        - 신경망의 학습처럼 ‘기계가 학습한다’는 개념을 의미하는 용어
        - 입력 데이터의 특성과 분포 경향 등에서 자동으로 데이터를 나누거나 재구성
        - 통계 기반 머신 러닝에서는 확률 개념이 크게 관여
    - 회귀 분석이 머신 러닝 및 신경망과의 연관 여부
        
        ![Untitled](인공지능(1)/Untitled%20155.png)
        
    - 입력 데이터의 회귀 분석 시 주로 데이터 식별 및 예측에 목적을 둠
    - 따라서 데이터를 선형 결합으로 나타내는 특성 이용
    - 회귀 분석 지도 학습
        - 정답 정보가 결합된 학습 데이터(또는 훈련 데이터)로 데이터의 특징을 모델링
    - 신경망 학습
        - 선형 분리로 변환하는 특성 이용
        - 선형 분리가 가능하면 회귀 분석과 같은 선형 결합 방법 사용
    - 자율 학습
        - 신경망을 사용하지 않는 경우
            - 입력 데이터의 정답을 모르는 상태에서 사용
            - 클러스터 분석, 차원 압축, 밀도 추정 등에 해당
        - 데이터 마이닝
            - 식별, 예측, 클러스터 분석 등 실행 시 데이터의 새로운 특징을 찾아내는 작업
    - 데이터 마이닝
        - 분류(Classification)
            - 일정한 집단에 대한 특징 정의를 통해 분류 및 구분을 추론
        - 군집화(Clustering)
            - 구체적인 특성을 공유하는 군집 검색
            - 군집화는 미리 정의된 특성에 대한 정보를 가지지 않는다는 점에서 분류와 다름
        - 연관성(Association)
            - 동시에 발생한 사건 간의 관계를 정의
        - 연속성(Sequencing)
            - 특정 기간에 걸쳐 발생하는 관계를 규명, 기간의 특성을 제외하면 연관성 분석과 유사
        - 예측(Forecasting)
            - 대용량 데이터 집합 내의 패턴을 기반으로 미래 예측
- 기저 함수
    - 정규 직교 기저
        - 좌표축  각각이 직교하는 선형 독립 상태에서 벡터로 나타내는 좌표축
        - 차원 수 만큼 표현이 가능하여 3차원 이상도 표현
            
            ![Untitled](인공지능(1)/Untitled%20156.png)
            
    - 회귀 분석을 정규 직교 기저로 설명하면, 선형 독립인 설명 변수의 합에 있는 목적 변수를 표현하는 것
    - 설명 변수가 선형 독립인 경우만 사용
    - 기저 함수 : 설명 변수를 함수 형태로 나타낸 것
    - 기저 함수 사용 시 개념
        - 일반화 선형 모델
            - 정규 분포 이외의 분포를 다루는 모델
        - 혼합 정규 모델
            - 혼합 정규 분포를 다루는 모델
            - 기저 함수와 기저 함수의 선형 결합으로 표현된 모델
            
            ![Untitled](인공지능(1)/Untitled%20157.png)
            

# 주요 기저 함수

- 주요 기저 함수
    - 기저 함수는 확률 분포에 따라 연속 확률 분포와 이산 확률 분포로 나뉨
        
        ![Untitled](인공지능(1)/Untitled%20158.png)
        
- 정규 분포
    - 가장 많이 사용되는 일반적인 분포 개념
    - 가우스 분포라고도 함
    - 실험의 측정 오차나 사회 현상 등 자연계 현상은 정규 분포를 따른 경향이 있음
    - 정규 분포를 엄격히 따르지 않아도 계산이나 모델의 단순화를 위해 데이터 분포를 정규 분포로 가정하는 경우가 많음
        
        ![Untitled](인공지능(1)/Untitled%20159.png)
        
- 감마 분포
    - 특정 수의 사건이 일어날 때까지 걸리는 시간에 관한 연속 확률 분포
    - 감마 함수 Γ는 자연수 집합 𝑁이 주어졌을 때 팩토리얼 𝑁!과 동일
    - 모양 매개 변수가 k고 크기 매개 변수가 𝜃일 때
        - 평균 : 𝑘𝜃
        - 분산 : 𝑘𝜃²
    
    ![Untitled](인공지능(1)/Untitled%20160.png)
    
- 지수 분포
    - 감마 분포의 특별한 형태로 사건이 일어나는 시간 간격의 확률 분포
    - 푸아송 분포와도 연관
    - 𝜆 : 단위 시간에 일어나는 평균 회수
        - 평균 : 1/𝜆
        - 분산 : 1 /𝜆²
    
    ![Untitled](인공지능(1)/Untitled%20161.png)
    
- 라플라스 분포
    - 보통의 정규분포보다 최고점이 더 높은 분포
    - 생물학, 재무, 경제 분야에서 데이터를 모형화 시 사용
        - 평균 : 𝜇
        - 분산 : 2𝜎²
        
        ![Untitled](인공지능(1)/Untitled%20162.png)
        
    
- 베타 분포
    - 2개의 변수를 갖는 특수 함수인 베타 함수를 이용한 분포
    - 베타 함수를 𝐵(𝛼,𝛽)로 나타낼 때, 𝛼>0, 𝛽>0, 0≤𝑥≤1(𝑥는 설명 변수)라는 조건 설정
    - 매개변수 𝛼, 𝛽를 바꾸면 다양한 분포로 표현 가능
    - 베이즈 통계학에서는 사전 분포 모델로 이용하는 경우가 많음
        
        ![Untitled](인공지능(1)/Untitled%20163.png)
        
- 디리클레 분포
    - 베타 분포를 다변량으로 확장한 것
    - 다변량 베타 분포라고도 함
    - 𝑘는 2 이상의 자연수, 𝛼는 매개변수,𝐵(𝛼)는 베타 함수, Γ는 감마 함수
        
        ![Untitled](인공지능(1)/Untitled%20164.png)
        
    - 연속 함수지만 2차원 평면에서는 연속 함수로 표현 불가
    - 어떤 현상이 일어나는 횟수를 확률 변수로 두는 분포가 다항 분포
    - 디리클레 분포는 확률 자체를 확률 변수로 두는 분포로 자연어 처리 등에 많이 사용
- 이항 분포
    - 베르누이 시행
        - 두 가지 경우 중 어느 하나가 나오는 가와 같은 실험
    - 이항 분포
        - 베르누이 시행을 여러 번 반복했을 때 확률 분포
    - 정규 분포나 푸아송 분포와 비슷
        
        ![Untitled](인공지능(1)/Untitled%20165.png)
        
    - 𝑿 는 확률 분포, 확률 𝒑 로 성공하는 실험에 있어 𝒑𝒌는 𝒌 번 성공할 확률, 𝒏 번 실행하는 경우 𝒏𝑪𝒌 의 조합만큼 성공할 확률이 나타날 가능성이 있음
    - 실패 회수의 확률과 함께 계산 시 𝒏 번의 독립된 시도에서 𝒌 회 성공할 확률을 나타낼 수 있음
- 음이항 분포
    - r번 성공하는데 필요한 시행 횟수 k의 분포
    - 생명 과학 분야에 많이 사용
        
        ![Untitled](인공지능(1)/Untitled%20166.png)
        
- 푸아송 분포
    - 일정 시간 간격에 걸쳐 평균 𝜆번 일어나는 현상이 k번 발생할 확률 분포 X
    - 푸아송 분포
        - 단위 시간에 사건이 일어날 확률
    - 지수 분포
        - 사건이 일어난 후 다시 발생할 때까지의 시간 간격에 관한 확률 밀도
    - 푸아송 분포와 지수 분포는 같은 사건의 발생 확률을 다른 측면에서 보는 것
        
        ![Untitled](인공지능(1)/Untitled%20167.png)
        
- 카이제곱 분포
    - 감마 분포의 특별한 형태
    - 통계적 추론에서는 카이제곱 검정으로 자주 이용
    - 집단을 몇 가지로 나눴을 때 크기가 작은 집단에 보편성이 있는지 확인
    - 임상 실험이나 사회 과학 설문 조사 등에 자주 사용
    - 평균 k는 2이상의 자연수, x는 설명 변수, Γ는 감마 함수
        
        ![Untitled](인공지능(1)/Untitled%20168.png)
        
- 초기하 분포
    - 반복하지 않는 시도에서 사건이 발생할 확률 분포
    - 예)
        - 빨간 구슬과 흰 구슬이 들어 있는 주머니에서 구슬을 빼는 시도를 n번 할 때 빨간 구슬 k를 꺼낼 수 있는 확률을 구할 수 있음
        - 구슬 전체 개수는 N, 원하는 구슬을 꺼낸 전체 성공 회수는 K
            
            ![Untitled](인공지능(1)/Untitled%20169.png)
            
- 코시 분포
    - 로렌츠 분포라고도 함
    - 물리학에서는 브라이트-위그너 분포라고 함
    - 분광학에서의 공명 현상 등 전자파와 방사선의 스펙트럼 분석 등에서 자주 사용
    - 𝜋는 원주율, 𝛾는 척도 모수 (확률 분포가 퍼져 있는 정도를 결정하는 집단의 수)
    - 정규 분포와 비슷한 모양
    - 그래프가 서서히 완만해 지며 중심이 그래프 아래로 잡힘
        
        ![Untitled](인공지능(1)/Untitled%20170.png)
        
- 로지스틱 분포
    - 확률 분포의 확률 변수가 특정값보다 작거나 같은 확률을 나타내는 누적 분포 함수가 로지스틱 함수인 분포
    - 형태는 정규 분포와 비슷하지만 그래프의 아래가 길어 평균에서 멀어지더라도 정규 분포처럼 곡선이 내려가지 않음
    - 𝑠는 표준 편차, 𝜇는 평균, 𝜋는 원주율
        
        ![Untitled](인공지능(1)/Untitled%20171.png)
        
- 베이불 분포
    - 물체의 부피와 강도의 관계를 나타내는 분포
    - 기기의 수명과 고장 시간 등의 신뢰성을 나타내는 지표로 이용
    - k(m)은 실행 회수, 𝜆(𝜂)는 단위 시간에 일어나는 평균 회수
        
        ![Untitled](인공지능(1)/Untitled%20172.png)
        
- 손실 함수와 경사 하강법
    - 회귀 분석을 사용하려는 함수가 존재할 때, 회귀 분석은 오차를 제곱한 것의 합계인 함수를 목적 함수로 설정
    - 목적 함수가 최소값이 되도록 계산
    - 목적 함수와 비슷한 함수로 손실 함수 사용
    - 손실 함수의 최소값 산출 식
        - 경사 하강법
            - 가중치 벡터 𝒘의 함수 𝑳 로 작성
            - 손실 함수를 어떤 점 𝑤𝑖로 편미분 한 것을 𝑳의 기울기를 ∇𝑳(𝒘)
            - 기울기 값이 ∇𝑳(𝒘∗) = 0 이 될 때의 𝒘∗ 가 구하려는 가중치
        - 최대 가능도 방법
    
    ![Untitled](인공지능(1)/Untitled%20173.png)
    

# 베이즈 통계학

- 베이즈 통계학
    - 베이즈 정리
    - 로짓 함수
    - 최대 가능도 추정
    - EM 알고리즘
    - 베이즈 판별 분석
- 베이즈 정리
    - 조건부 확률에 관한 법칙
    - 두 종류의 조건부 확률 사이의 관계 정의
        
        ![Untitled](인공지능(1)/Untitled%20174.png)
        
    - 승산
        - 확률 p가 있을 때 p/(1-p)를 계산한 수치
        - 수치가 높을 수록 이길 가능성이 작아짐
        - 이 값의 로그를 취한 것을 로짓 함수
        - 로지스틱 회귀 등에서 이용
    - 승산 비
        - 승산을 2개 사용해 비율을 취한 것
        - 두 집단에서 두 사건이 일어 났을 때 해당 사건이 일어나기 쉬운 정도
        - 임상 시험에서 투여한 약물의 효과가 어느 정도인가
        - 특정 두 시기에서 남녀의 인구 추세에 큰 차이가 있는지 등의 지표로 사용
        
        ![Untitled](인공지능(1)/Untitled%20175.png)
        
    - 예 1) 질병 검사의 양성 적중율
        - 질병 검사에서 질병에 걸릴 확률이 0.01
        - 병에 걸린 사람이 검사하면 0.99의 비율로 양성
        - 건강한 사람도 0.1의 비율로 양성이 된다고 가정
            
            ![Untitled](인공지능(1)/Untitled%20176.png)
            
    - 예2) 뺑소니 택시의 색상
        - 뺑소니 택시 사고 발생 시 목격자 증언에 따라 택시 색이 파란색이라고 증언
        - 거리에는 파란색과 녹색 두 종류 차량이 있으며 각각 15%, 85%의 비율 차지
        - 비슷한 상황으로 실험한 결과 목격자가 파란색이라고 했는데 실제 파란색일 비율이 80%일 경우, 실제 녹색일 확률은?
            
            ![Untitled](인공지능(1)/Untitled%20177.png)
            
- 최대 가능도 방법과 EM 알고리즘
    - 관측 데이터가 의미 있는 값과 노이즈로 구성된 경우
    - 의미 있는 값을 구할 때 최소제곱법 사용 시 손실 함수 설정
    - 손실 함수 대신 가능도 함수 설정
    - 가능도 함수가 최대가 되는 𝜃 설정 시 𝜃는 최대 가능도 추정량이라 함
    - 엔트로피가 높은 상태, 즉 노이즈가 가장 균형 있게 흩어져 있는 상태를 최대가능도 추정량으로 정해서 의미 있는 데이터를 구할 수 있음
    - 가능도 함수는 적분 형태가 나타날 때가 많아 로그 가능도 방정식 형태로 답을 구함
        
        ![Untitled](인공지능(1)/Untitled%20178.png)
        
    - 복잡한 가능도 함수에서 최대가능도 추정량을 직접 구할 수 없을 수 있음
    - 반복 계산으로 구하는 방법 선택
    - 의미 있는 값 x를 완전 데이터라고 하며 관찰할 수 있는 데이터 y는 불완전 데이터라고 함
    - x에 추가되는 어떤 작용 s(x)의 정보가 없으면 데이터 x를 한 가지 값으로 구할 수 없음
        
        ![Untitled](인공지능(1)/Untitled%20179.png)
        
    - EM(Expectation Maximization) 알고리즘
        - 숨겨진 변수를 포함하는 모델에 사용하는 가상 데이터 전체의 가능도 함수를 바탕으로 불완전한 데이터에서 최대가능도 추정량을 구하는 방법
        - 아래쪽 경계를 결정하기 위한 𝜃에 의존하는 볼록 함수 Q를 결정하는 E 단계와 Q에서의 𝜃를 극대화하는 M 단계를 반복 실행해 로그 가능도 함수의 최대값을 탐색
        - E 단계에서 구하는 Q는 사후 분포
            
            ![Untitled](인공지능(1)/Untitled%20180.png)
            
- 베이즈 추론
    - 데이터의 모집단 분포는 유일하지 않음
    - 관측하지 않은 데이터를 다룬다는 의미
    - 사전 분포(Prior Distribution) 혹은 주관 분포(Subjective Distribution)
        - 추론해야 하는 대상이 매개변수  𝜃일 때 확률 밀도 함수 𝝅(𝜃)
        
        ![Untitled](인공지능(1)/Untitled%20181.png)
        
    - 베이즈 추정량
        - 사후 분포의 평균 제곱 오차를 최소화하는 값
        - 사후 분포의 평균값
            
            ![Untitled](인공지능(1)/Untitled%20182.png)
            
    - 사후 메디안 추정량
        - 사후 분포의 평균 절대 오차를 최소화하는 값
        - 사후 분포의 중간값
            
            ![Untitled](인공지능(1)/Untitled%20183.png)
            
    - MAP 추정량
        
        ![Untitled](인공지능(1)/Untitled%20184.png)
        
    - 켤레 사전 분포
        - 사전 분포 𝜋(𝜃)와 사후 분포 𝑓(𝜃|𝑥)가 같은 유형의 분포를 보일 때를 켤레 사전 분포라 함
        - 사후 분포를 다루기 쉬운 특징
        - 𝜋(𝜃|𝛼)처럼 추가 매개변수가 들어가면 사후 분포에서는 𝑓(𝜃|𝑥,𝛼) 같은 형태로 표현
        - 𝛼를 하이퍼 파라미터라고 함
            
            ![Untitled](인공지능(1)/Untitled%20185.png)
            
            ![Untitled](인공지능(1)/Untitled%20186.png)
            
- 베이즈 판별 분석
    - 베이즈 추론의 예
        - 데이터 x가 어떤 모집단분포에 유래했는지 파악하는데 사용
        - 선형 판별 분석
            - 지도 학습의 훈련 데이터를 바탕으로 결정하는 경우가 많음
    - 베이즈 통계학 개념이 포함된 요소를 추가한 것이 베이즈 판별 분석
    - N가지 종류의 데이터 x와 추론 대상 매개변수 i가 있는 모집단 분포 f(x|i)와 사전 분포 𝜋(𝑖)로부터 사후 확률이 최대가 되는 모집단 분포 𝑓(𝑥|𝑖)의 유래를 판정
        
        ![Untitled](인공지능(1)/Untitled%20187.png)
        

# 베이지안 네트워크

- 베이지안 정리
    - 두 사건 A와 B에 대해서 B가 발생한 후에 사건 A가 발생할 확률을 계산하면 다음과 같은 식을 유도
    - 사전 조건이 없는 상태에서 사건 A가 발생할 확률 P(A)를 알고 어떤 조건 B를 전제로 한 A의 발생 확률 P(A|B)를 구하는 경우
        
        ![Untitled](인공지능(1)/Untitled%20188.png)
        
    - 베이즈 확률 적용 시 분모가 직접 주어지지 않은 경우,
        - 조건부 확률을 이용하여 계산
            
            ![Untitled](인공지능(1)/Untitled%20189.png)
            
        - 일반화 하여,
            
            ![Untitled](인공지능(1)/Untitled%20190.png)
            
    - 베이지안 정리의 특징
        - 명확한 사전 확률 요구
        - 각 사건들은 상호 배타적이며 독립적
    - 베이지안 정리의 단점
        - 실세계에서는 사전 확률을 명확히 유지하기 힘듦
        - 각 사건들의 연관성으로 인하여 상호 배타적이며 독립적이기 어려움
        - 잘 정의된 좁은 영역의 문제 해결에 유용함
    - 베이즈 정리의 의미
        - 증거에 따른 가설의 정확도
            - A를 가설로 간주하고 B를 증거로 간주하는 상황
            - 처음에는 가설 A에 대한 사전 확률 정보만 있지만 증거 B가 주어짐에 따라 정확도가 개설된 가설 A에 대한 사후 확률 P(A|B)를 베이즈 정리로 계산 가능
            - 연속된 사건이 발생할 경우 다음 확률의 계산이 가능하다는 의미
            - P(가설|증거)
        - 증상을 보고 원인을 추정하는 진단을 하는 경우
            - A를 원인으로 간주하고 B를 증상들로 간주하는 상황
            - 사전 확률 P(A)는 고장이나 질환이 생겼을 때 다른 정보가 없는 상태에서 A가 원인일 확률
            - 가능도 P(B|A)는 A가 원인일 때 B의 증상이 나타날 확률
            - 사후 확률 P(A|B)는 B의 증상이 나타날 때 원인이 A라고 판정할 확신도
            - P(원인|증상)
        - 기계 학습에 적용하는 경우
            - 학습 데이터를 D, 모델은 파라미터를 의미하는 𝜃로 정의
                
                ![Untitled](인공지능(1)/Untitled%20191.png)
                
            - 학습데이터를 나타내는 패턴에 대응하는 모델의 형태를 결정하는 파라미터를 찾기 위한 기본적 이론
            - 점진적 기계 학습을 가능하게 하는 프레임을 제공
            - 모델의 파라미터에 대한 사전 확률과 학습 데이터를 사용하여 모델의 파라미터에 대한 개선된 사후 확률을 결정하는 역할
            - 모델 파라미터에 대한 사후 확률을 가지고 있는 상태에서 추가적인 학습 데이터가 주어지면 이미 가지고 있는 사후 확률을 사전 확률로 가정하여 베이즈 정리를 새로 추가된 학습데이터에 적용하여 보다 개선된 확률 정보를 획득
- 베이지안 네트워크
    - 전문가 시스템은 주어진 조건에 적합한 답변을 하지만 추론 규칙이 정교하지 않음
    - 정의 : 확률 개념을 도입해 추론 규칙을 개선한 전문가 시스템으로 제안한 것
    - 특징
        - 불확실성을 포함한 사건의 예측과 관측 결과를 활용
        - 장애 진단에 사용하는 그래픽 확률 모델
        - 각 노드는 확률 변수
        - 확률 변수 사이의 확률 의존 관계 정보를 유향 그래프로 나타내는 네트워크로 시스템으로 구성
    - 베이지안 네트워크(Bayesian Network)
        - ‘빌리프 네트워크(Belief network)’라고도 불림
        - 집합을 조건부 독립으로 표현하는 확률의 그래픽 모델
        - 추론과 학습을 수행하기 위한 효과적인 알고리즘이 존재
        - 예를 들어, 질환과 증상 사이의 확률 관계를 나타낼 수 있음
        - 증상이 주어지면 다양한 질병의 존재 확률 계산 가능
    - 유향 그래픽 내에 인접한 노드 사이에는 조건부 확률 테이블이 할당
        - 은닉 마르코프 모델과 유사
            
            ![Untitled](인공지능(1)/Untitled%20192.png)
            
    - 단점
        - 네트워크가 복잡해 질 수록 조건부 확률 테이블 역시 복잡해 짐
        - 일반적인 네트워크 구조로는 확률 추론이 어려워 다양한 방법을 사용하여 사후 확률을 구해야 함
        - 무향 그래프이면서 루프가 없는 단일 결합 네트워크의 경우
            - 베이즈 정리를 이용하여 비교적 쉽게 임의의 사후 확률 산출 가능
        - 여러 개의 결합 네트워크의 경우
            - 확률 계산이 복잡해져 계산 비용 증가
    - 베이지안 네트워크의 단점 보안
        - 사후 확률을 구하는 효율적인 방법 연구
            - 사전에 단일 결합 트리 구조 그래프로 변환
            - 정밀도를 높여 다양한 샘플링 기법을 이용해 차이를 줄이는 방법
        - 노이즈 데이터가 포함되어 불확실성이 있는 상황
            - 센서 등으로 관측한 결과를 기반으로 진단과 인식 등의 추론 도구를 이용

# 베이지안 분류기

- 베이지안 분류기
    - 나이브(단순) 베이즈 분류기
        - 기계학습에서 데이터의 속성들 사이의 독립 사건을 가정하는 베이즈 정리를 적용한 확률 분류기의 일종
        - 특징
            - 지도 학습에 효율적
            - 모델 파라미터 추정 시 최대 가능도 법을 사용
            - 파라미터 추정에 사용되는 학습 데이터 양이 많이 필요하지 않음
            - 간단한 디자인과 단순한 가정이 실제 응용에 효율적으로 동작
    - 학습 규칙
        - 최대가능도법
            - 임의의 데이터가 얻어질 확률 P(x)를 가정
            - P(x)를 최대화하는 미지의 파리미터 w를 결정
            - w는 하나(벡터 또는 변수)가 결정
    - 베이즈 분류기
        - w가 확률적으로 결정
        - 확률을 업데이트 하는 학습을 수행
        - 확률을 업데이트 하기 위해 베이즈 정리를 적용
- 베이지안 분류기 개념
    
    ![Untitled](인공지능(1)/Untitled%20193.png)
    
    ![Untitled](인공지능(1)/Untitled%20194.png)
    
    - 파라미터 추정
        - 클래스 사전 확률
            - 클래스 간의 동일한 확률을 가정하여 산출
            - 학습 데이터로부터 클래스 확률 추정치 산출
        - 특징의 분포
            - 분포를 가정
            - 가우시안 분포, 베르누이 분포, 다항 분포 등
- 베이지안 분류기 학습
    
    ![Untitled](인공지능(1)/Untitled%20195.png)
    
    - 앞서 학습한 결과 각 입력 변수에 따른 평균과 분산이 산출
    - 2진 분류를 하고자 할 경우, 두 클래스에 속할 확률 중 큰 클래스를 선택
        
        ![Untitled](인공지능(1)/Untitled%20196.png)
        

# 확률 모델을 이용한 베이지안 분류기 생성

- 베이지안 분류기 예 1
    
    ![Untitled](인공지능(1)/Untitled%20197.png)
    
    ![Untitled](인공지능(1)/Untitled%20198.png)
    
    ![Untitled](인공지능(1)/Untitled%20199.png)
    
- 베이지안 분류기 예 2
    
    ![Untitled](인공지능(1)/Untitled%20200.png)
    
    ![Untitled](인공지능(1)/Untitled%20201.png)
    
- 베이지안 분류기의 문제점
    - 사전 조건부 확률이 0인 경우에는 어떤 학습 데이터가 들어오더라도 사후 확률이 0이 아닌 값을 가질 수 없음
    - 해결방법
        - 모든 속성값과 클래스 조합에 대한 빈도에 임의의 수를 더해 계산을 수행하도록 함
    - 입력 데이터가 실수일 경우 입력 데이터에서 각 입력 변수의 개수를 세는 부분이 불가, 사전 확률 산출의 문제 발생
        
        ![Untitled](인공지능(1)/Untitled%20202.png)
        
    - 해결 방법
        - 입력 변수의 구간을 임의로 구간별로 묶는 방법 사용

# 자율 학습

- 자율 학습
    - 학습이라는 것은 계산을 반복하면서 가중치 계수를 업데이트하는 작업
    - 가중치 계수 업데이트를 통해 모델이 되는 기저 함수와 분포에 접근하는 것을 의미
    - 자율 학습
        - 정답 정보가 없는 상태에서 학습을 통해 모델을 만드는 것
        - 데이터가 어떻게 구성되었는지를 알아내는 문제 범주에 속함
    - 특징
        - 통계의 밀도 추정과 연관
        - 데이터의 주요 특징을 요약하고 설명
- 데이터 마이닝
    - 정의
        - 대규모로 저장된 데이터 안에서 체계적이고 자동적으로 통계적 규칙이나 패턴을 찾아내는 것
        - KDD(Knowledge Discovery in Databases)
    - 방법론
        - 통계학적 방법론 : 통계학 쪽에서 발전
        - 기술적인 방법론 : 인공지능 진영에서 발전
    - 신용 평가 모델, 사기탐지 시스템, 장바구니 분석, 최적 포트폴리오 구축 등과 같은 산업 분야에 광범위하게 사용 됨
    - 연관성 분석
        - 거래나 사건을 포함하는 일련의 데이터로부터 연관 규칙을 발견하고 둘 이상의 품목들 간의 상호 연관성을 파악
        - 장바구니 분석 또는 친화성 분석 방법 등
            - 예 : 맥주와 기저귀의 연관성
            - 대형마트의 구매 패턴을 분석한 결과 주말에 아기용 기저귀를 구매하려 온 아버지들이 동시에 맥주를 구매, 이 패턴을 분석하여 월마트에서 기저귀와 맥주 패키지 판매를 통한 3배 매출 증가 효과 달성
    - 군집 분석
        - 이질적인 집단을 몇 개의 동질적인 소집단으로 세분화 하는 작업
        - 특징 : 사전에 정의된 집단이 없음
        - 여러 집단의 데이터들이 섞여 있고 각 데이터 소속 집단을 모르는 경우 유사한 속성을 갖는 데이터의 군집을 찾는 분석 방법
        - 주어진 데이터 중 유사한 것들만 몇몇의 집단으로 그룹화하여 각 집단의 성격을 파악하고 데이터 전체의 구조에 대한 이해를 돕도록 함
    - 의사결정 나무
        - 분류 문제를 해결하기 위해 매우 강력하고 유용한 데이터 마이닝 알고리즘
        - 분류를 하기 위한 목표 변수에 영향을 줄 수 있는 입력 변수들을 이용하여 최적의 분류를 위한 의사결정 규칙 생성
    - 클러스터 분석, 차원 압축 등을 주로 이용하며 그림을 결과로 표현하여 사람이 특징을 파악할 수 있도록 함
        - 장점 : 정보의 연관성을 파악하고 가치 있는 정보를 만들어 의사결정을 하고 이익을 극대화 시킴
        - 단점 : 자료에 의존하여 현상 해석 및 개선으로 인해 자료가 충실하지 못할 경우 오류 존재

# 클러스터 분석과 K-평균 알고리즘

- 클러스터 분석
    - 자율 학습의 대표적인 접근 방법
    - 평면상에 그려져 있는 점들을 그룹으로 분류
    - 그룹으로 만들 때 점들 사이가 어느 정도 떨어져 있는 지 측정 지표
    - 클러스터란 비슷한 특성을 가진 데이터들의 집단
    - 효율성
        - 수백 만의 데이터를 직접 확인하지 않고 각각 클러스터의 대표값만 확인하여 전체 데이터의 특성 파악 가능
    - 평면 상에 점을 그림
    - 데이터 특성 고려한 클러스터 정의
    - 데이터 집단의 대표점 검색
    - 데이터 마이닝의 대표적 예
        
        ![Untitled](인공지능(1)/Untitled%20203.png)
        
    - 기법
        - 파티셔닝 : data를 구간구간으로 나눠서 그들의 중심을 계산
        - k-평균 : 각 구간을 나누 다음 중심을 찾고 중심을 기준으로 구간을 다시 나누고 변경 사항이 있을 경우 다시 중심을 찾아가는 방식
        - k-중간점 : k-mean의 경계에 약한 단점을 보완. 중심 대신 중심객체를 사용
        - clara : 샘플링 k-medoids(중앙 객체)
        - clarans : 근처에 있는 데이터들끼리 샘플링
- k-평균 알고리즘
    - 클러스터 분석 시 자주 사용하는 방법
    - 과정
        - 우선 전체를 k개의 그룹으로 나눔
        - 각 점에 무작위로 그룹을 할당한 다음 그룹 각각의 중심과의 거리를 계산
        - 어떤 그룹에 속해 있는 점이 다른 그룹과 더 가깝다면 해당 점을 거리가 가까운 그룹으로 변경
        - 이러한 작업을 반복해서 가까운 점끼리 묶어 k개의 그룹을 분류
        - 임의의 점들의 분포를 이용하여 k개의 그룹으로 분리
        - 중심의 대표점을 선택
        - 각각의 점들과 그룹의 대표점들 간의 거리 측정
        - 재 그룹화
            
            ![Untitled](인공지능(1)/Untitled%20204.png)
            
    - 단점
        - 그룹의 중심점만 기준으로 삼다가 잘못된 그룹으로 할당할 수 있음
        - 계산 시간이 길어짐
    - 해결 방법
        - k-평균 알고리즘으로 여러 번 그룹을 생성하여 가장 좋은 결과를 채용
        - 그룹 생성 전 중심점을 되도록 떨어져 있게 설정하는 k-평균++ 알고리즘 사용
            - k-평균++ 알고리즘 : k-means 알고리즘의 초기값을 선택하는 알고리즘
    - 초기 그룹의 수인 k는 경험적으로 결정할 수도 있고 계산으로 산출하여 결정할 수도 있음
    - k결정 시 디리클레 모델 사용
        - 혼합 디리클레 모델은 베이즈 모델 기반의 접근 방식
        - 디리클레 분포가 다항분포의 결합 사전 분포라는 점을 이용
            - 다항 분포는 각 사건의 확률을 나타내는 분포이며 디리클레 분포는 발생하는 사건의 개수를 나타내는 분포
    - 혼합 디리클레 모델로 데이터를 그룹에 할당할 때 보통 기존의 가까운 그룹에 할당
    - 그룹 할당 과정을 EM 알고리즘으로 반복 실행하면 그룹 개수와 그룹 각각에 할당하는 데이터 분포 관찰 가능
        
        ![Untitled](인공지능(1)/Untitled%20205.png)
        

# GMM 알고리즘

- 가우시안 혼합 모델 개념
    
    ![Untitled](인공지능(1)/Untitled%20206.png)
    
    - 가우시안 분포가 여러 개 혼합된 클러스터링 알고리즘
    - 자연적인 현상 표현에 좋은 모델로 데이터 마이닝, 패턴 인식, 통계 분석 등에 광범위하게 적용
    - 여러 개의 가우시안 분포로부터 생성(수집)된 데이터들을 학습하여 각 데이터들이 어떤 가우시안 분포에서 생성된 것인지 확률로 추정 가능
    - 새로운 데이터가 입력될 경우 동일한 과정으로 클러스터링이 가능
    - K-means 클러스터링
        
        ![Untitled](인공지능(1)/Untitled%20207.png)
        
    - 3개의 클래스는 정해진 것이 아니라 추정되는 것으로 이것을 잠재 변수라 함
        
        ![Untitled](인공지능(1)/Untitled%20208.png)
        
    - 𝛾
        - 클러스터 k에 속할 확률
        - 어떤 클러스터에 얼마나 기여하고 있는가
            - 부담율(Responsibility)
- GMM의 예
    - 세 개의 gaussian 분포를 이용하여 데이터를 생성
        
        ![Untitled](인공지능(1)/Untitled%20209.png)
        
    - 3가지 분포의 평균, 매개변수, 가중치를 구하여 혼합 모델을 구축
    - 매개 변수 추정에 대한 다양한 알고리즘을 통해 GMM 모델 생성
    
    ![Untitled](인공지능(1)/Untitled%20210.png)
    
- GMM의 매개변수 추정
    - 목적
        - 관측되지 않는 클러스터 분포의 확률 분포와 각각의 클러스터에서의 gaussian 정규분포 매개 변수를 모두 측정하는 것
    - 단점
        - 확률분포 함수가 선형대수 방법으로 쉽게 구할 수 없는 복잡한 형태를 가진다는 점
    - 매개변수
        - 잠재 변수(latent variable) → 클러스터의 개수
        - 부담율(responsibility)
    - 잠재 변수
        - 관찰은 안되지만 데이터에 영향을 준 변수를 잠재 변수 또는 숨은 변수라 한다
        - 예)
            - 곤충의 질량과 크기를 나타내는 입력 데이터가 있을 때, 같은 곤충이라 생각하고 수집한 데이터를 클러스터링 한 결과 3개의 클러스터가 있는 것으로 추정
            - 같은 곤충에 3가지 종류가 있을 수 있다고 해석이 가능
            - 3개의 클러스터가 3개의 클래스라는 존재를 암시
    - 부담율(responsibility)
        - 관찰되지 않은 잠재 변수의 추정치가 어떤 클러스터에 포함될 것인지를 알려 주는 조건부 확률
            
            ![Untitled](인공지능(1)/Untitled%20211.png)
            
        - 𝛾𝑖k
            - 데이터 xi가 클러스터 k에서 생성되었을 확률
            - 확률적 추정값으로 0에서 1 사이의 실수값
- EM 알고리즘
    - 1958년 Hartley에 의해서 제안된 군집 알고리즘
    - K-Means 알고리즘과 마찬가지로 초기 모델을 생성한 후 반복 과정을 통하여 최적화된 모델을 생성
    - 반복 과정을 통하여 각 데이터들이 혼합 모델(Mixture Model)에 속할 가능성(Probability)을 조정하여 최적의 모델을 생성
    - K-Means 알고리즘에서는 유클리디언 거리 함수를 사용하는 반면에 EM 알고리즘은 log-likelihood 함수를 사용하여 모델의 적합성을 평가
    - EM 알고리즘은 최적해로 수렴한다는 것이 증명
    - EM은 초기 해에 따라 최종 해가 달라지는 욕심 알고리즘(Greedy algorithm)이고, 전역 최적 해가 아닌 지역 최적 해로 수렴할 수도 있음
    - E Step(Expectation Step)
        - 𝜋,𝜇,Σ 초기화로 부담율 𝛾를 산출
    - M Step(Maximization Step)
        - 현시점의 𝛾를 이용하여 𝜋,𝜇,Σ 를 산출
    - 각 단계가 임계치보다 작을 때까지 반복
        
        ![Untitled](인공지능(1)/Untitled%20212.png)
        
        <aside>
        💡 𝜋 : 클러스터의 혼합 계수
        
        𝜇 : 클러스터의 중심 벡터
        
        Σ : 클러스터의 공분산 행렬
        
        </aside>
        
    - 초기화
        
        ![Untitled](인공지능(1)/Untitled%20213.png)
        
    - Expectation Step
        
        ![Untitled](인공지능(1)/Untitled%20214.png)
        
    - Maximization Step
        
        ![Untitled](인공지능(1)/Untitled%20215.png)
        
        ![Untitled](인공지능(1)/Untitled%20216.png)
        
    - 반복과정
        
        ![Untitled](인공지능(1)/Untitled%20217.png)
        
    - 가능도
        - 가능도는 모든 데이터 점 X가 모델에서 생성된 확률
        - 로그를 취한 후 -1을 곱한 값
        - 가능도나 로그 가능도를 최적화할 때에는 확률을 극대화 하기 때문에 -1을 곱한 음의 로그 가능도를 오차 함수로 정의
    - 가능도 오차 함수
        
        ![Untitled](인공지능(1)/Untitled%20218.png)
        
- GMM 모델 응용 예
    - 퍼지 영상 분할(Fuzzy image segmentation)
        - 교통 분야의 영상 처리 시 사고와 혼잡의 구분을 위해 GMM 모델을 적용
        - 기존 영상 처리나 CV에서는 하나의 픽셀을 하나의 패턴에만 할당
        - 만약 패턴들이 gaussian 분포라면, 퍼지 영상 분할은 gaussian 혼합 모델 분포에 따름
        - 공간적으로 정규화 된 혼합 모델로서 더 현실적이고 계산적으로 효율적인 분할 방법
    - 문서의 주제(Topic Model)
        - 문서가 N개의 서로 다른 단어와 전체 크기가 V인 어휘로 구성되어 있고, 각 단어는 K개의 주제 중 하나에 해당한다고 가정
        - 이러한 단어들의 분포는 K 개의 서로 다른 V 차원 범주형 분포(Categorical distribution)의 혼합 모델로 표현
        - 사전 분포(Prior distribution)는 아주 작은 수의 단어만 0이 아닌 확률을 가지고 있는 스파스 분포(Sparse distribution)를 만들기 위해 토픽 분포를 묘사하는 매개변수 사용
        - 자연적 집단화(natural clustering)를 이용하기 위해, 몇몇 종류의 추가 조건은 단어들의 토픽 유사성(identities)을 사용

# 회귀 분석

- 회귀 분석 개념
    - 회귀 분석은 지도 학습의 하나로 학습 데이터에 부합되는 출력 값이 실수인 함수를 찾는 문제
    - 예
        - 나이와 키의 상관 관계를 통해 임의의 나이를 입력했을 때의 키 값 구하기
        - 중고차의 주행 거리와 가격과의 관계를 통해 임의의 주행 거리 입력 시 중고차 가격 구하기
- 초기 가설
    - 회귀 분석은 학습 데이터에 따른 결과값이 주어지면 임의의 데이터를 입력했을 때 실수인 결과값을 찾을 수 있는 함수를 구하는 문제
    - 회귀 분석의 가설은 학습 데이터를 이용한 학습 전 함수를 가정하는 것
    - 예
        - 나이와 몸무게 추정 데이터
        - 16명의 데이터를 수집하여 학습
            
            ![Untitled](인공지능(1)/Untitled%20219.png)
            
    - 초기 가설 함수는 1차 함수로 선택
    - 주어진 학습 데이터를 통해 가장 쉽게 추정할 수 있는 방법
    - 단순하므로 정확한 값 산출은 어려움
    - 가설
        - ℎ 𝑥 = 𝑤0𝑥 + 𝑤1
        - 우리가 구하고자 하는 것은 𝑤0, 𝑤1인 파라미터
        - 𝑤0: 기울기, 𝑤1: 절편
    - 기울기 w0와 절편 w1의 값을 이용하면 다양한 위치와 기울기의 직선을 생성
    - h(x)는 x에 대한 예측치
    - 임의의 기울기와 절편으로 구성한 1차 가설 함수
    - 기울기와 절편을 어떻게 설정해야 가설 함수가 데이터와 부합할 것인지를 학습
        
        ![Untitled](인공지능(1)/Untitled%20220.png)
        
- 오차 함수
    - 가설로 설립한 함수와 최종 학습된 함수의 차이를 데이터를 학습하면서 줄이도록 하는 것이 학습 목표
    - 오차 함수란 주어진 임의의 데이터 입력값으로 표현되는 실제 출력값과 가설 함수를 통해 출력된 시뮬레이션 출력값과의 차이를 계산하는 함수
    - 최종 학습 목표는 모든 데이터에 대해 실제 출력값과 시뮬레이션으로 출력되는 출력값과의 오차가 최소가 되도록 하는 것
    - 제곱 오차 함수(Sum of Square Error; SSE) 계열 사용
        
        ![Untitled](인공지능(1)/Untitled%20221.png)
        
    - 제곱 오차의 경우 N(데이터 개수)에 영향을 받을 수 있으므로 평균 제곱 오차(Mean Square Error; MSE)를 사용
    - w0와 w1을 결정하면 평균 제곱 오차 E 계산이 가능
    - 데이터가 직선 상에 나란히 있지 않기 때문에 E가 완전히 0이 되지는 않음
    - 1차 선형 회귀는 평균 제곱 오차를 사용할 경우 2차 함수로 오차 함수를 표현할 수 있으며 이 때 오차 함수의 최소값을 구하면 그 때의 파라미터가 최종 학습 목표인 회귀 함수의 파라미터로 결정
        
        ![Untitled](인공지능(1)/Untitled%20222.png)
        
- 경사 하강법(Gradient Descent Method)
    - 평균 제곱 오차 함수가 최소가 되는 위치를 근사화 하기 위한 학습 방법
    - E가 가장 작아지는 w0과 w1을 구하는 방법 중 하나
    - 초기 w0과 w1를 결정하고 이 점에서의 기울기를 확인하여 E가 감소하는 방향으로 w0과 w1를 조금만 이동
    - 이 절차를 여러 번 반복하여 최종적으로 E가 가장 작아지는 점인 w0과 w1에 도착
    - At(w0 w1), E를 w0과 w1로 편미분하여 벡터로 표현 : E의 기울기
        
        ![Untitled](인공지능(1)/Untitled%20223.png)
        
    - E를 최소화하기 위해서는 E의 기울기의 반대 방향인 - 𝛻𝒘𝐸 로 진행
        
        ![Untitled](인공지능(1)/Untitled%20224.png)
        
        ![Untitled](인공지능(1)/Untitled%20225.png)
        
    - 학습 규칙을 이용한 매개 변수 산출
        - 초기 값 w0 = 10, w1 = 165로 가정할 경우 기울기 값은 각각 dw0 = 5046.3, dw1 = 301.8
        - 초기 매개 변수 값을 이용하여 각 매개 변수 범위 내에서 학습을 수행
            - 𝑤0=10, 𝑤1=165, 𝛼=0.001, threshold=0.1
            
            ![Untitled](인공지능(1)/Untitled%20226.png)
            
    - 그래프의 해석
        - 평균 제곱 오차(MSE) :  49.03 𝑐𝑚2
        - 표준 편차(Standard Deviation) : 약 7.0 cm
            - 오차가 정규 분포를 따른다는 가정 하에, 전체 68%의 데이터 점에서 오차가 7.0 이하라는 의미
    - 일반적인 경사 하강법
        - 산출된 해는 부분적은 극소값(Local Minima)
        - E가 복잡한 다차원일 경우 가장 최소가 되는 극소값(Global Minima)를 구하는 것은 어려운 문제
            - 다양한 초기값에서 경사 하강법을 시도하여 E가 작아진 지점을 최소값으로 선택

# 서포트 벡터 머신

- 서포트 벡터 머신(Support Vector Machine; SVM)
    - 데이터 분포를 나누는 기준을 결정하는 지도 학습 모델 중 하나
    - 회귀 분석의 관점
        - 데이터에 맞춘 직선과 곡선의 특징을 분석
    - SVM의 관점
        - 어떤 패턴으로 데이터를 분류한 후 데이터 사이의 거리에 따라 어떤 카테고리에 속할 것인지 판단
        - 다층 퍼셉트론 같은 신경망을 이용한 데이터 분류와 유사
    - 2개의 클래스에 속한 데이터 사이의 거리를 최대화 하면서 가운데를 통과하는 식별 함수를 구함
    - 서포트 벡터 : 마진 영역의 가장 자리에 해당하는 위치에 있는 데이터
        - 마진 영역 : 서포트 벡터와 식별 함수 사이의 공간
            
            ![Untitled](인공지능(1)/Untitled%20227.png)
            
    - 커널 트릭 방법을 이용하여 비선형 식별 함수를 결정할 수도 있음
    - 선형 식별 함수
        - 마진 최대화 시 선형 식별 함수는 모든 훈련 데이터를 올바르게 식별할 수 있어야 함
        - 훈련 데이터와 식별 함수의 값이 0이 되는 식별 초평면과의 최소 거리가 가장 크도록 최적화
        - 라그랑주 승수법으로 해결
        - 식별 함수는 서포트 벡터만 결정할 수 있음
    - 식별 함수
        - 입력 데이터의 내적만 이용하는 형태
        - 내적은 비선형 식별 함수를 만드는 방법을 찾는 데도 이용
    - 커널 트릭
        - 차원을 높이지 않고도 차원을 올리는 효과
        - 다항식과 가우스 함수 등의 커널 함수를 이용하여 원래 공간의 데이터 분포를 선형 분리할 수 있는 공간으로 변형하는 것
        - 주성분 분석과 클러스터 분석 등에 응용
    - 소프트 마진
        - 실제 데이터는 깔끔하게 분리가 되지 않으므로 잘못 식별된 데이터에 패널티를 설정하여 오차에 대응
        - 마진 최대화와 패널티를 함께 고려해 최적화 하는 방법
    - 손실 함수는 경첩(hinge) 모양을 나타내므로 경첩 함수 또는 경첩 손실 함수라고도 함
        
        ![Untitled](인공지능(1)/Untitled%20228.png)
        

# 의사결정 트리

- 결정 트리 종류
    
    ![Untitled](인공지능(1)/Untitled%20229.png)
    
- ID3
    - 정답 데이터를 이용해 결정 트리를 만드는 알고리즘의 하나
    - 의사 결정 트리를 기반으로 모든 데이터를 제대로 분류할 때까지 노드 추가
    - 데이터를 제대로 분류하는 결정 트리는 여러 개가 나올 수 있음
    - 분류 효율성과 의사 결정 트리의 일반성을 고려해 최대한 단순한 형태가 되는 것이 목표
    - ID3 장점
        - 계산 비용이 적음
        - 학습된 결과를 사람이 이해하기 쉽고, 누락값에 대한 처리 가능
        - 분류와 관련 없는 속성에 대해서도 처리 가능
    - ID3 단점
        - 연속형 수치 사용이 불가
        - 속성의 값이 많을 경우 가지의 수도 많아짐(overfitting)
- ID3에서 결정 트리 만드는 방법
    - 모든 데이터를 포함한 하나의 노드로 구성된 트리에서 시작
    - 반복적인 노드 분할 과정
        - 분할 속성(splitting attribute)을 선택
        - 속성값에 따라 서브 트리(subtree)를 생성
        - 데이터를 속성값에 따라 분배
    - 분할 속성 결정
        - 어떤 속성을 선택하는 것이 효율적인가?
            - 가능하면 분할 결과가 동질적인 것으로 만드는 속성
        - Entropy(엔트로피)
            - 동질적인 정도 측정 가능 척도
            - 원 의미는 정보량(Amount of Information) 측정 목적의 척도
            - p(c) : 부류 c에 속하는 것의 비율
                
                ![Untitled](인공지능(1)/Untitled%20230.png)
                
            - 2개의 부류가 존재할 경우
                
                ![Untitled](인공지능(1)/Untitled%20231.png)
                
    - Information Gain
        - 원래의 엔트로피와 세부 클래스로 분할된 후의 엔트로피의 차이
        - information Gain이 클수록 분류하기 좋다는 것을 의미
        - ID3 알고리즘은 information Gain를 사용하여 노드를 결정
        - IG = I − 𝐼𝑟𝑒𝑠
        - 𝐼𝑟𝑒𝑠: 특정 속성으로 분할한 후의 각 부분 집합의 정보량의 가중 평균
            
            ![Untitled](인공지능(1)/Untitled%20232.png)
            
        - 단점
            - 속성값이 많은 것을 선호하여 선택하게 됨
            - 예) 학번 또는 이름 등
            - 속성값이 많으면 데이터 집합을 많은 부분집합으로 분할
            - 작은 부분 집합은 동질적인 성향으로 분석
        - 개선
            - 정보 이득비(Information Gain Ratio)
            - 지니 지수(Gini Index)
    - Information Gain Ratio
        - 속성값이 많은 속성에 대해서 패널티를 부여
        - I(A)
            - 속성 A의 속성 값을 클래스로 간주하여 계산한 엔트로피
            - 속성 값이 많을 수록 커지는 경향
                
                ![Untitled](인공지능(1)/Untitled%20233.png)
                
    - 지니 지수
        - 데이터의 균형과 불균형에 대한 지수
            
            ![Untitled](인공지능(1)/Untitled%20234.png)
            
        - 속성 A에 대한 지니 지수의 가중 평균 값
            
            ![Untitled](인공지능(1)/Untitled%20235.png)
            
        - 지니 지수 이득(gini index gain)
            
            ![Untitled](인공지능(1)/Untitled%20236.png)
            
- 랜덤 포레스트
    - 서포트 벡터 머신과 함께 데이터의 분포를 분류하는 방법
    - 무작위로 뽑은 데이터를 이용해 학습하면서 많은 결정 트리를 구축하며 의사 결정 트리를 만들 때 마다 결정 트리 구성을 약간씩 변화
    - 최종 단계에서 구축한 결정 트리 중 최적의 결정 트리를 선택
    - 타당성 검증
        - 모델을 만들 때는 모델이 얼마나 정확한 결과를 계산하는지를 객관적으로 측정
            
            ![Untitled](인공지능(1)/Untitled%20237.png)
            
- 식별 모델의 평가와 ROC 곡선
    - ROC 곡선(receiver Operating Characteristic curve)
        - 식별 모델의 성능을 평가하는 방법
        - 제 2차 세계 대전 때 수신된 레이더 신호에서 적 전투기를 찾으려는 미국의 레이더 연구에서 탄생한 개념
    - ROC 곡선의 생성
        - 데이터의 정답 결과 세트와 식별 결과 세트를 준비해 혼동 행렬을 생성
        - 식별 결과가 두 종류인 경우 혼동 행렬은 2X2 표 형태가 됨
        - 혼동 행렬은 참 긍정(True Positive; TP), 거짓 부정(False Negative; FN), 거짓 긍정(False Positive; FP), 참 부정(True Negative; TN)의 개수를 나타내는 행렬
            
            ![Untitled](인공지능(1)/Untitled%20238.png)
            
    - 혼동 행렬
        
        ![Untitled](인공지능(1)/Untitled%20239.png)
        
- ROC 곡선을 이용한 평가
    - AUC 값
        - AUC는 ROC 곡선의 아래 부분 면적 값을 의미
        - 0.9 이상이면 정확도가 높음을 의미
    - 왼쪽 위에서 곡선까지 거리
        - AUC 값이 높을수록 ROC 곡선은 왼쪽 위에 가까운 형태
        - 왼쪽 위에서 곡선의 거리인 a가 짧으면 짧을 수록 성능이 좋음
    - Youden Index
        - AUC 값과 길이 0.5의 대각선 사이 거리 b가 가장 멀 때 ‘진양성율 + 거짓양성율 = c’로 표현되는 값
        - 이 값이 큰 모델은 가장 좋은 평가를 받은 매개변수
        
        ![Untitled](인공지능(1)/Untitled%20240.png)